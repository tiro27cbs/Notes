<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.42">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Data Science Research Team">
<meta name="dcterms.date" content="2025-03-27">

<title>17&nbsp; Hyper-Parameter Optimization (HPO) in Machine Learning ‚Äì Machine Learning and Deep Learning Notes</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter16.html" rel="next">
<link href="./chapter14.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-8da5b4427184b79ecddefad3d342027e.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter15.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Hyper-Parameter Optimization (HPO) in Machine Learning</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Machine Learning and Deep Learning Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">üöÄ Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Fundamentals of Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Building an End-to-End Machine Learning Pipeline</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Unsupervised Learning: Clustering Techniques</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Supervised Learning: Regression and Classification</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Dimensionality Reduction Methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tree-Based Models and Ensemble Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter6v2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Support Vector Machines and Model Evaluation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter7.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Outlier Detection and Recommendation Systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter8.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Gradient Descent: Optimization in Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter9.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Neural Networks and Deep Learning Foundations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter10.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Batch Normalization, RNN, Distributed Deep Learning and Tensorflow</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter11.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Variants of Recurrent Neural Networks (RNNs): LSTM, GRU, BiLSTM</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter12.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Autoencoders</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter13.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Convolutional Neural Networks</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter14.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Adversarial Examples and Generative Models: A Deep Dive into Robustness and Synthetic Data Generation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter15.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Hyper-Parameter Optimization (HPO) in Machine Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter16.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Federated Learning and Transfer Learning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter17.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Reinforcement Learning: Concepts and Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter18.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Explainable Artificial Intelligence (XAI): Concepts and Challenges</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">17.1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#what-is-hyper-parameter-optimization" id="toc-what-is-hyper-parameter-optimization" class="nav-link" data-scroll-target="#what-is-hyper-parameter-optimization"><span class="header-section-number">17.1.1</span> What is Hyper-Parameter Optimization?</a></li>
  <li><a href="#why-is-hpo-important-in-machine-learning" id="toc-why-is-hpo-important-in-machine-learning" class="nav-link" data-scroll-target="#why-is-hpo-important-in-machine-learning"><span class="header-section-number">17.1.2</span> Why is HPO Important in Machine Learning?</a></li>
  <li><a href="#analogy-baking-a-cake---ingredients-vs.-oven-settings" id="toc-analogy-baking-a-cake---ingredients-vs.-oven-settings" class="nav-link" data-scroll-target="#analogy-baking-a-cake---ingredients-vs.-oven-settings"><span class="header-section-number">17.1.3</span> Analogy: Baking a Cake - Ingredients vs.&nbsp;Oven Settings</a></li>
  </ul></li>
  <li><a href="#sec-understanding-hyperparameters" id="toc-sec-understanding-hyperparameters" class="nav-link" data-scroll-target="#sec-understanding-hyperparameters"><span class="header-section-number">17.2</span> Understanding Hyper-Parameters</a>
  <ul class="collapse">
  <li><a href="#types-of-hyper-parameters-in-neural-networks" id="toc-types-of-hyper-parameters-in-neural-networks" class="nav-link" data-scroll-target="#types-of-hyper-parameters-in-neural-networks"><span class="header-section-number">17.2.1</span> Types of Hyper-Parameters in Neural Networks</a></li>
  <li><a href="#role-of-hyper-parameters-in-model-performance" id="toc-role-of-hyper-parameters-in-model-performance" class="nav-link" data-scroll-target="#role-of-hyper-parameters-in-model-performance"><span class="header-section-number">17.2.2</span> Role of Hyper-Parameters in Model Performance</a></li>
  <li><a href="#why-hyper-parameters-cannot-be-learned-like-normal-parameters" id="toc-why-hyper-parameters-cannot-be-learned-like-normal-parameters" class="nav-link" data-scroll-target="#why-hyper-parameters-cannot-be-learned-like-normal-parameters"><span class="header-section-number">17.2.3</span> Why Hyper-Parameters Cannot Be Learned Like Normal Parameters</a></li>
  </ul></li>
  <li><a href="#challenges-in-hyper-parameter-optimization" id="toc-challenges-in-hyper-parameter-optimization" class="nav-link" data-scroll-target="#challenges-in-hyper-parameter-optimization"><span class="header-section-number">17.3</span> Challenges in Hyper-Parameter Optimization</a>
  <ul class="collapse">
  <li><a href="#computational-challenges" id="toc-computational-challenges" class="nav-link" data-scroll-target="#computational-challenges"><span class="header-section-number">17.3.1</span> Computational Challenges</a></li>
  </ul></li>
  <li><a href="#sec-initialization" id="toc-sec-initialization" class="nav-link" data-scroll-target="#sec-initialization"><span class="header-section-number">17.4</span> Parameter Initialization</a>
  <ul class="collapse">
  <li><a href="#importance-of-weight-initialization" id="toc-importance-of-weight-initialization" class="nav-link" data-scroll-target="#importance-of-weight-initialization"><span class="header-section-number">17.4.1</span> Importance of Weight Initialization</a></li>
  </ul></li>
  <li><a href="#sec-learning-rate" id="toc-sec-learning-rate" class="nav-link" data-scroll-target="#sec-learning-rate"><span class="header-section-number">17.5</span> Learning Rate Strategies</a>
  <ul class="collapse">
  <li><a href="#importance-of-learning-rate" id="toc-importance-of-learning-rate" class="nav-link" data-scroll-target="#importance-of-learning-rate"><span class="header-section-number">17.5.1</span> Importance of Learning Rate</a></li>
  <li><a href="#learning-rate-scheduling-techniques" id="toc-learning-rate-scheduling-techniques" class="nav-link" data-scroll-target="#learning-rate-scheduling-techniques"><span class="header-section-number">17.5.2</span> Learning Rate Scheduling Techniques</a></li>
  </ul></li>
  <li><a href="#hyper-parameter-search-strategies" id="toc-hyper-parameter-search-strategies" class="nav-link" data-scroll-target="#hyper-parameter-search-strategies"><span class="header-section-number">17.6</span> Hyper-Parameter Search Strategies</a>
  <ul class="collapse">
  <li><a href="#optimization-techniques" id="toc-optimization-techniques" class="nav-link" data-scroll-target="#optimization-techniques"><span class="header-section-number">17.6.1</span> Optimization Techniques</a></li>
  </ul></li>
  <li><a href="#hyper-parameter-optimization-frameworks" id="toc-hyper-parameter-optimization-frameworks" class="nav-link" data-scroll-target="#hyper-parameter-optimization-frameworks"><span class="header-section-number">17.7</span> Hyper-Parameter Optimization Frameworks</a>
  <ul class="collapse">
  <li><a href="#popular-frameworks" id="toc-popular-frameworks" class="nav-link" data-scroll-target="#popular-frameworks"><span class="header-section-number">17.7.1</span> Popular Frameworks</a></li>
  </ul></li>
  <li><a href="#best-practices" id="toc-best-practices" class="nav-link" data-scroll-target="#best-practices"><span class="header-section-number">17.8</span> Best Practices</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">17.9</span> Conclusion</a>
  <ul class="collapse">
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways"><span class="header-section-number">17.9.1</span> Key Takeaways</a></li>
  <li><a href="#future-trends" id="toc-future-trends" class="nav-link" data-scroll-target="#future-trends"><span class="header-section-number">17.9.2</span> Future Trends</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Hyper-Parameter Optimization (HPO) in Machine Learning</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Data Science Research Team </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 27, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="17.1">
<h2 data-number="17.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">17.1</span> Introduction</h2>
<section id="what-is-hyper-parameter-optimization" class="level3" data-number="17.1.1">
<h3 data-number="17.1.1" class="anchored" data-anchor-id="what-is-hyper-parameter-optimization"><span class="header-section-number">17.1.1</span> What is Hyper-Parameter Optimization?</h3>
<p>Hyper-Parameter Optimization (HPO) is a critical process in machine learning that involves finding the most effective configuration of model hyperparameters to maximize performance. Unlike standard model parameters that are learned during training, hyperparameters are set before the learning process begins and significantly impact model performance.</p>
</section>
<section id="why-is-hpo-important-in-machine-learning" class="level3" data-number="17.1.2">
<h3 data-number="17.1.2" class="anchored" data-anchor-id="why-is-hpo-important-in-machine-learning"><span class="header-section-number">17.1.2</span> Why is HPO Important in Machine Learning?</h3>
<p>Hyperparameter optimization is crucial because: - The right hyperparameters can dramatically improve model accuracy - Poorly chosen hyperparameters can lead to underfitting or overfitting - Manual tuning becomes impractical for complex models with many hyperparameters</p>
</section>
<section id="analogy-baking-a-cake---ingredients-vs.-oven-settings" class="level3" data-number="17.1.3">
<h3 data-number="17.1.3" class="anchored" data-anchor-id="analogy-baking-a-cake---ingredients-vs.-oven-settings"><span class="header-section-number">17.1.3</span> Analogy: Baking a Cake - Ingredients vs.&nbsp;Oven Settings</h3>
<p>Think of hyperparameters like oven settings when baking a cake: - Model Parameters = Cake Ingredients (learned during mixing) - Hyperparameters = Oven Temperature and Baking Time (set before baking) - Just as precise oven settings can make or break a cake, hyperparameters can make or break a machine learning model</p>
</section>
</section>
<section id="sec-understanding-hyperparameters" class="level2" data-number="17.2">
<h2 data-number="17.2" class="anchored" data-anchor-id="sec-understanding-hyperparameters"><span class="header-section-number">17.2</span> Understanding Hyper-Parameters</h2>
<section id="types-of-hyper-parameters-in-neural-networks" class="level3" data-number="17.2.1">
<h3 data-number="17.2.1" class="anchored" data-anchor-id="types-of-hyper-parameters-in-neural-networks"><span class="header-section-number">17.2.1</span> Types of Hyper-Parameters in Neural Networks</h3>
<p>Common hyperparameters include: - <strong>Learning Rate</strong>: Controls the step size during optimization. - <strong>Batch Size</strong>: Determines the number of samples per training batch. - <strong>Dropout Rate</strong>: Fraction of neurons dropped during training to prevent overfitting. - <strong>Regularization Strength</strong>: Penalizes large weights to improve generalization. - <strong>Momentum</strong>: Accelerates gradient descent by considering past gradients. - <strong>Network Architecture Parameters</strong>: Includes the number of layers, units per layer, and activation functions.</p>
<section id="python-example-of-hyperparameters" class="level4" data-number="17.2.1.1">
<h4 data-number="17.2.1.1" class="anchored" data-anchor-id="python-example-of-hyperparameters"><span class="header-section-number">17.2.1.1</span> Python Example of Hyperparameters</h4>
<div id="ccc63d8c" class="cell" data-execution_count="1">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Hyperparameters</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>learning_rate <span class="op">=</span> <span class="fl">0.001</span>  <span class="co"># Learning rate</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span>        <span class="co"># Batch size</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>dropout_rate <span class="op">=</span> <span class="fl">0.5</span>     <span class="co"># Dropout rate</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>regularization <span class="op">=</span> <span class="fl">1e-4</span>  <span class="co"># L2 regularization strength</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>(<span class="dv">10</span>,)),</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dropout(dropout_rate),</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span><span class="st">'sigmoid'</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>tf.keras.optimizers.Adam(learning_rate<span class="op">=</span>learning_rate),</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-stderr">
<pre><code>C:\Users\roess\Documents\repos\Notes\myvenv312\Lib\site-packages\keras\src\layers\core\dense.py:87: UserWarning:

Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.
</code></pre>
</div>
</div>
</section>
</section>
<section id="role-of-hyper-parameters-in-model-performance" class="level3" data-number="17.2.2">
<h3 data-number="17.2.2" class="anchored" data-anchor-id="role-of-hyper-parameters-in-model-performance"><span class="header-section-number">17.2.2</span> Role of Hyper-Parameters in Model Performance</h3>
<p>Hyperparameters play a critical role in determining the behavior and effectiveness of machine learning models. They influence several key aspects, including: - <strong>Model Complexity</strong>: Hyperparameters such as the number of layers in a neural network or the depth of a decision tree directly affect how complex the model can be. - <strong>Training Dynamics</strong>: Parameters like the learning rate or batch size control how the model learns during training, impacting convergence speed and stability. - <strong>Regularization</strong>: Techniques like dropout rates or L2 regularization coefficients help prevent overfitting by constraining the model‚Äôs capacity. - <strong>Generalization Capabilities</strong>: Proper tuning of hyperparameters ensures the model performs well on unseen data, balancing underfitting and overfitting.</p>
</section>
<section id="why-hyper-parameters-cannot-be-learned-like-normal-parameters" class="level3" data-number="17.2.3">
<h3 data-number="17.2.3" class="anchored" data-anchor-id="why-hyper-parameters-cannot-be-learned-like-normal-parameters"><span class="header-section-number">17.2.3</span> Why Hyper-Parameters Cannot Be Learned Like Normal Parameters</h3>
<p>Unlike model parameters (e.g., weights in a neural network), hyperparameters cannot be optimized directly during training due to several reasons: - <strong>No Direct Gradient Computation</strong>: Hyperparameters are not part of the model‚Äôs computational graph, so their impact on the loss function cannot be differentiated to compute gradients. - <strong>Discrete or Categorical Nature</strong>: Many hyperparameters, such as the number of layers or choice of activation functions, are not continuous, making gradient-based optimization infeasible. - <strong>Computational Expense</strong>: Evaluating different hyperparameter configurations often requires retraining the model from scratch, which can be computationally expensive and time-consuming.</p>
</section>
</section>
<section id="challenges-in-hyper-parameter-optimization" class="level2" data-number="17.3">
<h2 data-number="17.3" class="anchored" data-anchor-id="challenges-in-hyper-parameter-optimization"><span class="header-section-number">17.3</span> Challenges in Hyper-Parameter Optimization</h2>
<section id="computational-challenges" class="level3" data-number="17.3.1">
<h3 data-number="17.3.1" class="anchored" data-anchor-id="computational-challenges"><span class="header-section-number">17.3.1</span> Computational Challenges</h3>
<ol type="1">
<li><strong>Expensive Function Evaluations</strong>
<ul>
<li>Large models require significant computational resources</li>
<li>Each hyperparameter configuration needs full model training</li>
</ul></li>
<li><strong>High-Dimensional Search Space</strong>
<ul>
<li>Multiple hyperparameters to tune</li>
<li>Complex interactions between hyperparameters</li>
</ul></li>
<li><strong>No Direct Gradient Access</strong>
<ul>
<li>Traditional optimization techniques fail</li>
<li>Cannot use standard gradient descent methods</li>
</ul></li>
<li><strong>Overfitting Risks</strong></li>
</ol>
<div id="0853f321" class="cell" data-execution_count="2">
<details class="code-fold">
<summary>Show the code</summary>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Define input variables</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>input_shape <span class="op">=</span> (<span class="dv">10</span>,)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>num_classes <span class="op">=</span> <span class="dv">2</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>X_train <span class="op">=</span> np.random.rand(<span class="dv">100</span>, <span class="dv">10</span>)  <span class="co"># Random training data</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>y_train <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, size<span class="op">=</span>(<span class="dv">100</span>,))  <span class="co"># Random binary labels</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>X_val <span class="op">=</span> np.random.rand(<span class="dv">20</span>, <span class="dv">10</span>)  <span class="co"># Random validation data</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>y_val <span class="op">=</span> np.random.randint(<span class="dv">0</span>, <span class="dv">2</span>, size<span class="op">=</span>(<span class="dv">20</span>,))  <span class="co"># Random binary labels</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a simple model</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>, input_shape<span class="op">=</span>input_shape),</span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>    tf.keras.layers.Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>model.<span class="bu">compile</span>(</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>    optimizer<span class="op">=</span>tf.keras.optimizers.Adam(learning_rate<span class="op">=</span><span class="fl">0.01</span>),</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    loss<span class="op">=</span><span class="st">'sparse_categorical_crossentropy'</span>,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>    metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> demonstrate_overfitting(model, X_train, y_train, X_val, y_val):</span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co">    Demonstrate model overfitting with poor hyperparameter selection</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Overfitting scenario with no regularization</span></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    history <span class="op">=</span> model.fit(X_train, y_train, </span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>                        epochs<span class="op">=</span><span class="dv">100</span>,  <span class="co"># Too many epochs</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>                        batch_size<span class="op">=</span><span class="dv">4</span>,  <span class="co"># Very small batch size</span></span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>                        validation_data<span class="op">=</span>(X_val, y_val),</span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>                        verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot training and validation loss</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    epochs <span class="op">=</span> np.arange(<span class="dv">1</span>, <span class="dv">101</span>)</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    train_loss <span class="op">=</span> history.history[<span class="st">'loss'</span>]</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    val_loss <span class="op">=</span> history.history[<span class="st">'val_loss'</span>]</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, train_loss, label<span class="op">=</span><span class="st">'Training Loss'</span>)</span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>    plt.plot(epochs, val_loss, label<span class="op">=</span><span class="st">'Validation Loss'</span>)</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Overfitting Demonstration'</span>)</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a><span class="co"># Call the function to demonstrate overfitting</span></span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a>demonstrate_overfitting(model, X_train, y_train, X_val, y_val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter15_files/figure-html/cell-3-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="sec-initialization" class="level2" data-number="17.4">
<h2 data-number="17.4" class="anchored" data-anchor-id="sec-initialization"><span class="header-section-number">17.4</span> Parameter Initialization</h2>
<section id="importance-of-weight-initialization" class="level3" data-number="17.4.1">
<h3 data-number="17.4.1" class="anchored" data-anchor-id="importance-of-weight-initialization"><span class="header-section-number">17.4.1</span> Importance of Weight Initialization</h3>
<section id="problems-with-poor-initialization" class="level4" data-number="17.4.1.1">
<h4 data-number="17.4.1.1" class="anchored" data-anchor-id="problems-with-poor-initialization"><span class="header-section-number">17.4.1.1</span> Problems with Poor Initialization</h4>
<ul>
<li>Symmetry Breaking</li>
<li>Vanishing/Exploding Gradients</li>
<li>Slow Convergence</li>
</ul>
</section>
<section id="initialization-techniques" class="level4" data-number="17.4.1.2">
<h4 data-number="17.4.1.2" class="anchored" data-anchor-id="initialization-techniques"><span class="header-section-number">17.4.1.2</span> Initialization Techniques</h4>
<ol type="1">
<li><strong>Random Initialization</strong>
<ul>
<li>Simple approach</li>
<li>Risks include uniform weight distribution</li>
</ul></li>
<li><strong>Xavier (Glorot) Initialization</strong>
<ul>
<li>Maintains variance across layers</li>
<li>Works well for sigmoid and tanh activations</li>
</ul></li>
<li><strong>He Initialization</strong>
<ul>
<li>Optimized for ReLU activation functions</li>
<li>Prevents vanishing/exploding gradients</li>
</ul></li>
</ol>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_initializations(input_shape, num_classes):</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Compare different weight initialization techniques</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    initializers <span class="op">=</span> {</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'random_normal'</span>: tf.keras.initializers.RandomNormal(),</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'xavier'</span>: tf.keras.initializers.GlorotUniform(),</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'he'</span>: tf.keras.initializers.HeNormal()</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, initializer <span class="kw">in</span> initializers.items():</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>        model <span class="op">=</span> tf.keras.Sequential([</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(<span class="dv">64</span>, activation<span class="op">=</span><span class="st">'relu'</span>, </span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>                                   kernel_initializer<span class="op">=</span>initializer, </span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>                                   input_shape<span class="op">=</span>input_shape),</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>            tf.keras.layers.Dense(num_classes, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        ])</span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f"Initialization: </span><span class="sc">{</span>name<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Model compilation and training would follow</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
</section>
<section id="sec-learning-rate" class="level2" data-number="17.5">
<h2 data-number="17.5" class="anchored" data-anchor-id="sec-learning-rate"><span class="header-section-number">17.5</span> Learning Rate Strategies</h2>
<section id="importance-of-learning-rate" class="level3" data-number="17.5.1">
<h3 data-number="17.5.1" class="anchored" data-anchor-id="importance-of-learning-rate"><span class="header-section-number">17.5.1</span> Importance of Learning Rate</h3>
<p>The learning rate determines the step size during optimization: - Too high: Model may diverge - Too low: Extremely slow convergence</p>
<section id="learning-rate-effects" class="level4" data-number="17.5.1.1">
<h4 data-number="17.5.1.1" class="anchored" data-anchor-id="learning-rate-effects"><span class="header-section-number">17.5.1.1</span> Learning Rate Effects</h4>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> plot_learning_rate_effects(model, X_train, y_train, learning_rates):</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Visualize model performance with different learning rates</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    histories <span class="op">=</span> []</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> lr <span class="kw">in</span> learning_rates:</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        model.optimizer.learning_rate.assign(lr)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>        history <span class="op">=</span> model.fit(X_train, y_train, epochs<span class="op">=</span><span class="dv">50</span>, verbose<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>        histories.append(history)</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Plot learning curves</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> lr, history <span class="kw">in</span> <span class="bu">zip</span>(learning_rates, histories):</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>        plt.plot(history.history[<span class="st">'loss'</span>], label<span class="op">=</span><span class="ss">f'LR = </span><span class="sc">{</span>lr<span class="sc">}</span><span class="ss">'</span>)</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>    plt.title(<span class="st">'Learning Rate Impact'</span>)</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    plt.xlabel(<span class="st">'Epochs'</span>)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    plt.ylabel(<span class="st">'Loss'</span>)</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>    plt.legend()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="learning-rate-scheduling-techniques" class="level3" data-number="17.5.2">
<h3 data-number="17.5.2" class="anchored" data-anchor-id="learning-rate-scheduling-techniques"><span class="header-section-number">17.5.2</span> Learning Rate Scheduling Techniques</h3>
<p>Learning rate scheduling involves strategies to reduce the learning rate during training to improve convergence and performance. A good learning rate is crucial for effective training:</p>
<ul>
<li><strong>Too High</strong>: Training may diverge (‚ÄúGradient Descent‚Äù).</li>
<li><strong>Too Low</strong>: Training will eventually converge to the optimum, but at the cost of very long training time.</li>
</ul>
<section id="finding-a-good-learning-rate" class="level4" data-number="17.5.2.1">
<h4 data-number="17.5.2.1" class="anchored" data-anchor-id="finding-a-good-learning-rate"><span class="header-section-number">17.5.2.1</span> Finding a Good Learning Rate</h4>
<p>To find an optimal learning rate: 1. Train the model for a few hundred iterations, exponentially increasing the learning rate from a very small value to a very large value. 2. Examine the learning curve and select a learning rate slightly lower than the point where the learning curve starts shooting back up. 3. Reinitialize the model and train it with the selected learning rate.</p>
</section>
<section id="common-scheduling-techniques" class="level4" data-number="17.5.2.2">
<h4 data-number="17.5.2.2" class="anchored" data-anchor-id="common-scheduling-techniques"><span class="header-section-number">17.5.2.2</span> Common Scheduling Techniques</h4>
<ol type="1">
<li><strong>Power Scheduling</strong>
<ul>
<li>The learning rate decreases as a power function of the iteration number ( t ):<br>
[ (t) = ]
<ul>
<li>( _0 ): Initial learning rate<br>
</li>
<li>( c ): Power (commonly set to 1)<br>
</li>
<li>( s ): Steps (hyperparameter)</li>
</ul></li>
</ul></li>
<li><strong>Exponential Scheduling</strong>
<ul>
<li>The learning rate decreases exponentially:<br>
[ (t) = _0 ^{t/s} ]
<ul>
<li>Gradually reduces the learning rate by a factor of 10 every ( s ) steps.</li>
</ul></li>
</ul></li>
<li><strong>Piecewise Constant Scheduling</strong>
<ul>
<li>The learning rate remains constant for specific epoch ranges and then decreases:
<ul>
<li>Example: ( _0 = 0.1 ) for the first 5 epochs, then ( _1 = 0.001 ) for the next 50 epochs.</li>
</ul></li>
</ul></li>
<li><strong>Performance-Based Scheduling</strong>
<ul>
<li>The learning rate is reduced adaptively based on validation performance:
<ul>
<li>Measure validation error every ( N ) steps.<br>
</li>
<li>Reduce the learning rate by a factor ( ) when the error stops improving.</li>
</ul></li>
</ul></li>
</ol>
</section>
</section>
</section>
<section id="hyper-parameter-search-strategies" class="level2" data-number="17.6">
<h2 data-number="17.6" class="anchored" data-anchor-id="hyper-parameter-search-strategies"><span class="header-section-number">17.6</span> Hyper-Parameter Search Strategies</h2>
<section id="optimization-techniques" class="level3" data-number="17.6.1">
<h3 data-number="17.6.1" class="anchored" data-anchor-id="optimization-techniques"><span class="header-section-number">17.6.1</span> Optimization Techniques</h3>
<ol type="1">
<li><strong>Babysitting or Trial and Error (Grad Student Descent - GSD)</strong>
<ul>
<li>100% manual tuning.</li>
<li>Widely used but highly inefficient for complex models.</li>
<li>Challenges include large number of hyperparameters, time-consuming evaluations, and non-linear interactions.</li>
</ul></li>
<li><strong>Grid Search (GS)</strong>
<ul>
<li>Most commonly used method.</li>
<li>Exhaustive search or brute-force approach.</li>
<li>Evaluates the Cartesian product of user-specified finite sets of values.</li>
<li><strong>Problem</strong>: Inefficient for high-dimensional hyperparameter spaces as the number of evaluations grows exponentially with the number of hyperparameters.</li>
</ul></li>
<li><strong>Random Search (RS)</strong>
<ul>
<li>Similar to GS but randomly selects a pre-defined number of samples within bounds.</li>
<li>Can explore a larger search space with a limited budget compared to GS.</li>
<li><strong>Problem</strong>: May perform unnecessary evaluations as it does not exploit previously well-performing regions.</li>
</ul></li>
<li><strong>Gradient-Based Optimization</strong>
<ul>
<li>Traditional technique that moves in the opposite direction of the largest gradient to locate the next point.</li>
<li>Fast convergence speed to reach a local optimum.</li>
<li>Commonly used to optimize learning rates in neural networks.</li>
<li><strong>Problem</strong>: May get stuck in local optima and is not suitable for discrete or categorical hyperparameters.</li>
</ul></li>
</ol>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV, RandomizedSearchCV</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> compare_search_strategies(model, param_grid, X, y):</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a><span class="co">    Compare Grid Search vs Random Search</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="co">    """</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    grid_search <span class="op">=</span> GridSearchCV(model, param_grid, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    random_search <span class="op">=</span> RandomizedSearchCV(model, param_grid, n_iter<span class="op">=</span><span class="dv">10</span>, cv<span class="op">=</span><span class="dv">5</span>)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    grid_search.fit(X, y)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>    random_search.fit(X, y)</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Best Grid Search Parameters:"</span>, grid_search.best_params_)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">"Best Random Search Parameters:"</span>, random_search.best_params_)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="hyper-parameter-optimization-frameworks" class="level2" data-number="17.7">
<h2 data-number="17.7" class="anchored" data-anchor-id="hyper-parameter-optimization-frameworks"><span class="header-section-number">17.7</span> Hyper-Parameter Optimization Frameworks</h2>
<section id="popular-frameworks" class="level3" data-number="17.7.1">
<h3 data-number="17.7.1" class="anchored" data-anchor-id="popular-frameworks"><span class="header-section-number">17.7.1</span> Popular Frameworks</h3>
<ol type="1">
<li><strong>Scikit-learn</strong>
<ul>
<li>GridSearchCV</li>
<li>RandomizedSearchCV</li>
</ul></li>
<li><strong>TensorFlow/Keras</strong>
<ul>
<li>KerasTuner</li>
<li>Trieste</li>
</ul></li>
<li><strong>Optuna</strong>
<ul>
<li>Advanced Bayesian optimization</li>
<li>Efficient HPO for deep learning</li>
</ul></li>
</ol>
</section>
</section>
<section id="best-practices" class="level2" data-number="17.8">
<h2 data-number="17.8" class="anchored" data-anchor-id="best-practices"><span class="header-section-number">17.8</span> Best Practices</h2>
<ol type="1">
<li>Start with small dataset subsets</li>
<li>Use logarithmic scaling for hyperparameters</li>
<li>Employ adaptive optimization methods</li>
<li>Parallelize tuning when possible</li>
<li>Use separate validation data</li>
</ol>
</section>
<section id="conclusion" class="level2" data-number="17.9">
<h2 data-number="17.9" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">17.9</span> Conclusion</h2>
<section id="key-takeaways" class="level3" data-number="17.9.1">
<h3 data-number="17.9.1" class="anchored" data-anchor-id="key-takeaways"><span class="header-section-number">17.9.1</span> Key Takeaways</h3>
<ul>
<li>Hyper-Parameter Optimization is crucial for model performance</li>
<li>Multiple strategies exist for exploring hyperparameter space</li>
<li>Computational efficiency is key</li>
<li>Continuous learning and adaptation of techniques</li>
</ul>
</section>
<section id="future-trends" class="level3" data-number="17.9.2">
<h3 data-number="17.9.2" class="anchored" data-anchor-id="future-trends"><span class="header-section-number">17.9.2</span> Future Trends</h3>
<ul>
<li>Automated Machine Learning (AutoML)</li>
<li>Meta-Learning approaches</li>
<li>More sophisticated optimization algorithms</li>
</ul>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "Óßã";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter14.html" class="pagination-link" aria-label="Adversarial Examples and Generative Models: A Deep Dive into Robustness and Synthetic Data Generation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Adversarial Examples and Generative Models: A Deep Dive into Robustness and Synthetic Data Generation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter16.html" class="pagination-link" aria-label="Federated Learning and Transfer Learning">
        <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Federated Learning and Transfer Learning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>