\relax 
\providecommand*\new@tpo@label[2]{}
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\newlabel{preface}{{}{3}{}{chapter*.2}{}}
\@writefile{toc}{\contentsline {chapter}{Preface}{3}{chapter*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {1}🚀 Introduction}{4}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{introduction}{{1}{4}{🚀 Introduction}{chapter.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Fundamentals of Machine Learning}{6}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{fundamentals-of-machine-learning}{{2}{6}{Fundamentals of Machine Learning}{chapter.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Types of Machine Learning Systems}{6}{section.2.1}\protected@file@percent }
\newlabel{types-of-machine-learning-systems}{{2.1}{6}{Types of Machine Learning Systems}{section.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}1. Supervised Learning}{6}{subsection.2.1.1}\protected@file@percent }
\newlabel{supervised-learning}{{2.1.1}{6}{1. Supervised Learning}{subsection.2.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1.1}Key Techniques}{6}{subsubsection.2.1.1.1}\protected@file@percent }
\newlabel{key-techniques}{{2.1.1.1}{6}{Key Techniques}{subsubsection.2.1.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}2. Unsupervised Learning}{7}{subsection.2.1.2}\protected@file@percent }
\newlabel{unsupervised-learning}{{2.1.2}{7}{2. Unsupervised Learning}{subsection.2.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2.1}Key Techniques}{7}{subsubsection.2.1.2.1}\protected@file@percent }
\newlabel{key-techniques-1}{{2.1.2.1}{7}{Key Techniques}{subsubsection.2.1.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}3. Semi-Supervised Learning}{8}{subsection.2.1.3}\protected@file@percent }
\newlabel{semi-supervised-learning}{{2.1.3}{8}{3. Semi-Supervised Learning}{subsection.2.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}4. Reinforcement Learning}{8}{subsection.2.1.4}\protected@file@percent }
\newlabel{reinforcement-learning}{{2.1.4}{8}{4. Reinforcement Learning}{subsection.2.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.1}Example Concept}{8}{subsubsection.2.1.4.1}\protected@file@percent }
\newlabel{example-concept}{{2.1.4.1}{8}{Example Concept}{subsubsection.2.1.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4.2}Main Challenges of Machine Learning}{8}{subsubsection.2.1.4.2}\protected@file@percent }
\newlabel{main-challenges-of-machine-learning}{{2.1.4.2}{8}{Main Challenges of Machine Learning}{subsubsection.2.1.4.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Building an End-to-End Machine Learning Pipeline}{11}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{building-an-end-to-end-machine-learning-pipeline}{{3}{11}{Building an End-to-End Machine Learning Pipeline}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Look at the Big Picture}{11}{section.3.1}\protected@file@percent }
\newlabel{look-at-the-big-picture}{{3.1}{11}{Look at the Big Picture}{section.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Get the Data}{11}{section.3.2}\protected@file@percent }
\newlabel{get-the-data}{{3.2}{11}{Get the Data}{section.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.1}Python Example}{12}{subsection.3.2.1}\protected@file@percent }
\newlabel{python-example}{{3.2.1}{12}{Python Example}{subsection.3.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.2}Dataset Splitting}{12}{subsection.3.2.2}\protected@file@percent }
\newlabel{dataset-splitting}{{3.2.2}{12}{Dataset Splitting}{subsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2.3}Python Example}{12}{subsection.3.2.3}\protected@file@percent }
\newlabel{python-example-1}{{3.2.3}{12}{Python Example}{subsection.3.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Discover and Visualize the Data}{13}{section.3.3}\protected@file@percent }
\newlabel{discover-and-visualize-the-data}{{3.3}{13}{Discover and Visualize the Data}{section.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}Python Example}{13}{subsection.3.3.1}\protected@file@percent }
\newlabel{python-example-2}{{3.3.1}{13}{Python Example}{subsection.3.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Feature Scaling and Normalization}{14}{section.3.4}\protected@file@percent }
\newlabel{feature-scaling-and-normalization}{{3.4}{14}{Feature Scaling and Normalization}{section.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}Common Methods}{14}{subsection.3.4.1}\protected@file@percent }
\newlabel{common-methods}{{3.4.1}{14}{Common Methods}{subsection.3.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}Python Example}{15}{subsection.3.4.2}\protected@file@percent }
\newlabel{python-example-3}{{3.4.2}{15}{Python Example}{subsection.3.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}Prepare the Data for Machine Learning Algorithms}{15}{section.3.5}\protected@file@percent }
\newlabel{prepare-the-data-for-machine-learning-algorithms}{{3.5}{15}{Prepare the Data for Machine Learning Algorithms}{section.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}Common Preprocessing Steps}{15}{subsection.3.5.1}\protected@file@percent }
\newlabel{common-preprocessing-steps}{{3.5.1}{15}{Common Preprocessing Steps}{subsection.3.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}Using Scikit-Learn Pipelines}{16}{section.3.6}\protected@file@percent }
\newlabel{using-scikit-learn-pipelines}{{3.6}{16}{Using Scikit-Learn Pipelines}{section.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Example Pipeline}{16}{subsection.3.6.1}\protected@file@percent }
\newlabel{example-pipeline}{{3.6.1}{16}{Example Pipeline}{subsection.3.6.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Select and Train a Model}{16}{section.3.7}\protected@file@percent }
\newlabel{select-and-train-a-model}{{3.7}{16}{Select and Train a Model}{section.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7.1}Training Example}{16}{subsection.3.7.1}\protected@file@percent }
\newlabel{training-example}{{3.7.1}{16}{Training Example}{subsection.3.7.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}Fine-Tune Your Model}{17}{section.3.8}\protected@file@percent }
\newlabel{fine-tune-your-model}{{3.8}{17}{Fine-Tune Your Model}{section.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.1}Common Techniques}{17}{subsection.3.8.1}\protected@file@percent }
\newlabel{common-techniques}{{3.8.1}{17}{Common Techniques}{subsection.3.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.8.2}Example}{17}{subsection.3.8.2}\protected@file@percent }
\newlabel{example}{{3.8.2}{17}{Example}{subsection.3.8.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Model Evaluation Metrics}{18}{section.3.9}\protected@file@percent }
\newlabel{model-evaluation-metrics}{{3.9}{18}{Model Evaluation Metrics}{section.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.9.1}Python Example}{18}{subsection.3.9.1}\protected@file@percent }
\newlabel{python-example-4}{{3.9.1}{18}{Python Example}{subsection.3.9.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.10}Present Your Solution}{19}{section.3.10}\protected@file@percent }
\newlabel{present-your-solution}{{3.10}{19}{Present Your Solution}{section.3.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.11}Launch, Monitor, and Maintain the System}{19}{section.3.11}\protected@file@percent }
\newlabel{launch-monitor-and-maintain-the-system}{{3.11}{19}{Launch, Monitor, and Maintain the System}{section.3.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.12}Summary Checklist}{20}{section.3.12}\protected@file@percent }
\newlabel{summary-checklist}{{3.12}{20}{Summary Checklist}{section.3.12}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Unsupervised Learning: Clustering Techniques}{21}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{unsupervised-learning-clustering-techniques}{{4}{21}{Unsupervised Learning: Clustering Techniques}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}What is Unsupervised Learning?}{21}{section.4.1}\protected@file@percent }
\newlabel{what-is-unsupervised-learning}{{4.1}{21}{What is Unsupervised Learning?}{section.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}Why Use It?}{21}{subsection.4.1.1}\protected@file@percent }
\newlabel{why-use-it}{{4.1.1}{21}{Why Use It?}{subsection.4.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}Analogy}{21}{subsection.4.1.2}\protected@file@percent }
\newlabel{analogy}{{4.1.2}{21}{Analogy}{subsection.4.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}K-Means Clustering}{21}{section.4.2}\protected@file@percent }
\newlabel{k-means-clustering}{{4.2}{21}{K-Means Clustering}{section.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}What is K-Means?}{21}{subsection.4.2.1}\protected@file@percent }
\newlabel{what-is-k-means}{{4.2.1}{21}{What is K-Means?}{subsection.4.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}Use Cases}{22}{subsection.4.2.2}\protected@file@percent }
\newlabel{use-cases}{{4.2.2}{22}{Use Cases}{subsection.4.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}How It Works}{22}{subsection.4.2.3}\protected@file@percent }
\newlabel{how-it-works}{{4.2.3}{22}{How It Works}{subsection.4.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.4}Convergence \& Efficiency}{23}{subsection.4.2.4}\protected@file@percent }
\newlabel{convergence-efficiency}{{4.2.4}{23}{Convergence \& Efficiency}{subsection.4.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.5}Centroid Initialization Strategies}{23}{subsection.4.2.5}\protected@file@percent }
\newlabel{centroid-initialization-strategies}{{4.2.5}{23}{Centroid Initialization Strategies}{subsection.4.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.6}Example: Webstore Segmentation}{23}{subsection.4.2.6}\protected@file@percent }
\newlabel{example-webstore-segmentation}{{4.2.6}{23}{Example: Webstore Segmentation}{subsection.4.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.7}Pros}{23}{subsection.4.2.7}\protected@file@percent }
\newlabel{pros}{{4.2.7}{23}{Pros}{subsection.4.2.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.8}Cons}{24}{subsection.4.2.8}\protected@file@percent }
\newlabel{cons}{{4.2.8}{24}{Cons}{subsection.4.2.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Mini-Batch K-Means}{24}{section.4.3}\protected@file@percent }
\newlabel{mini-batch-k-means}{{4.3}{24}{Mini-Batch K-Means}{section.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}How It Works}{24}{subsection.4.3.1}\protected@file@percent }
\newlabel{how-it-works-1}{{4.3.1}{24}{How It Works}{subsection.4.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Benefits}{24}{subsection.4.3.2}\protected@file@percent }
\newlabel{benefits}{{4.3.2}{24}{Benefits}{subsection.4.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Evaluating Clustering Quality}{25}{section.4.4}\protected@file@percent }
\newlabel{evaluating-clustering-quality}{{4.4}{25}{Evaluating Clustering Quality}{section.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Silhouette Score}{25}{subsection.4.4.1}\protected@file@percent }
\newlabel{silhouette-score}{{4.4.1}{25}{Silhouette Score}{subsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1.1}Formula:}{25}{subsubsection.4.4.1.1}\protected@file@percent }
\newlabel{formula}{{4.4.1.1}{25}{Formula:}{subsubsection.4.4.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.2}Elbow Method}{26}{subsection.4.4.2}\protected@file@percent }
\newlabel{elbow-method}{{4.4.2}{26}{Elbow Method}{subsection.4.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.3}Elbow vs Silhouette}{26}{subsection.4.4.3}\protected@file@percent }
\newlabel{elbow-vs-silhouette}{{4.4.3}{26}{Elbow vs Silhouette}{subsection.4.4.3}{}}
\gdef \LT@i {\LT@entry 
    {3}{83.29605pt}\LT@entry 
    {3}{228.931pt}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}DBSCAN: Density-Based Clustering}{27}{section.4.5}\protected@file@percent }
\newlabel{dbscan-density-based-clustering}{{4.5}{27}{DBSCAN: Density-Based Clustering}{section.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}What is DBSCAN?}{27}{subsection.4.5.1}\protected@file@percent }
\newlabel{what-is-dbscan}{{4.5.1}{27}{What is DBSCAN?}{subsection.4.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.2}Key Terms}{27}{subsection.4.5.2}\protected@file@percent }
\newlabel{key-terms}{{4.5.2}{27}{Key Terms}{subsection.4.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.3}DBSCAN Steps}{27}{subsection.4.5.3}\protected@file@percent }
\newlabel{dbscan-steps}{{4.5.3}{27}{DBSCAN Steps}{subsection.4.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.4}Pros}{28}{subsection.4.5.4}\protected@file@percent }
\newlabel{pros-1}{{4.5.4}{28}{Pros}{subsection.4.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.5}Cons}{28}{subsection.4.5.5}\protected@file@percent }
\newlabel{cons-1}{{4.5.5}{28}{Cons}{subsection.4.5.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.6}Parameter Tuning}{28}{subsection.4.5.6}\protected@file@percent }
\newlabel{parameter-tuning}{{4.5.6}{28}{Parameter Tuning}{subsection.4.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.7}Applications}{28}{subsection.4.5.7}\protected@file@percent }
\newlabel{applications}{{4.5.7}{28}{Applications}{subsection.4.5.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Clustering with Hierarchical Clustering}{29}{section.4.6}\protected@file@percent }
\newlabel{clustering-with-hierarchical-clustering}{{4.6}{29}{Clustering with Hierarchical Clustering}{section.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.1}What is Hierarchical Clustering?}{29}{subsection.4.6.1}\protected@file@percent }
\newlabel{what-is-hierarchical-clustering}{{4.6.1}{29}{What is Hierarchical Clustering?}{subsection.4.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.2}Types of Hierarchical Clustering}{29}{subsection.4.6.2}\protected@file@percent }
\newlabel{types-of-hierarchical-clustering}{{4.6.2}{29}{Types of Hierarchical Clustering}{subsection.4.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.3}Distance Metrics}{29}{subsection.4.6.3}\protected@file@percent }
\newlabel{distance-metrics}{{4.6.3}{29}{Distance Metrics}{subsection.4.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.4}Linkage Criteria}{29}{subsection.4.6.4}\protected@file@percent }
\newlabel{linkage-criteria}{{4.6.4}{29}{Linkage Criteria}{subsection.4.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.5}Example: Agglomerative Clustering}{30}{subsection.4.6.5}\protected@file@percent }
\newlabel{example-agglomerative-clustering}{{4.6.5}{30}{Example: Agglomerative Clustering}{subsection.4.6.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.6}Python Example}{30}{subsection.4.6.6}\protected@file@percent }
\newlabel{python-example-5}{{4.6.6}{30}{Python Example}{subsection.4.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6.7}Advantages}{31}{subsection.4.6.7}\protected@file@percent }
\newlabel{advantages}{{4.6.7}{31}{Advantages}{subsection.4.6.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Final Notes}{31}{section.4.7}\protected@file@percent }
\newlabel{final-notes}{{4.7}{31}{Final Notes}{section.4.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Supervised Learning: Regression and Classification}{33}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{supervised-learning-regression-and-classification}{{5}{33}{Supervised Learning: Regression and Classification}{chapter.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Introduction to Supervised Learning}{33}{section.5.1}\protected@file@percent }
\newlabel{introduction-to-supervised-learning}{{5.1}{33}{Introduction to Supervised Learning}{section.5.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}K-Nearest Neighbors (KNN)}{33}{section.5.2}\protected@file@percent }
\newlabel{k-nearest-neighbors-knn}{{5.2}{33}{K-Nearest Neighbors (KNN)}{section.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Overview}{33}{subsection.5.2.1}\protected@file@percent }
\newlabel{overview}{{5.2.1}{33}{Overview}{subsection.5.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.2}How KNN Works}{34}{subsection.5.2.2}\protected@file@percent }
\newlabel{how-knn-works}{{5.2.2}{34}{How KNN Works}{subsection.5.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.3}Distance Metrics}{36}{subsection.5.2.3}\protected@file@percent }
\newlabel{distance-metrics-1}{{5.2.3}{36}{Distance Metrics}{subsection.5.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.4}Choosing K Value}{36}{subsection.5.2.4}\protected@file@percent }
\newlabel{choosing-k-value}{{5.2.4}{36}{Choosing K Value}{subsection.5.2.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.5}Preprocessing for KNN}{37}{subsection.5.2.5}\protected@file@percent }
\newlabel{preprocessing-for-knn}{{5.2.5}{37}{Preprocessing for KNN}{subsection.5.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.6}Advantages and Disadvantages}{37}{subsection.5.2.6}\protected@file@percent }
\newlabel{advantages-and-disadvantages}{{5.2.6}{37}{Advantages and Disadvantages}{subsection.5.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.7}Applications}{37}{subsection.5.2.7}\protected@file@percent }
\newlabel{applications-1}{{5.2.7}{37}{Applications}{subsection.5.2.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Linear Regression}{38}{section.5.3}\protected@file@percent }
\newlabel{linear-regression}{{5.3}{38}{Linear Regression}{section.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Overview}{38}{subsection.5.3.1}\protected@file@percent }
\newlabel{overview-1}{{5.3.1}{38}{Overview}{subsection.5.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}The Model}{38}{subsection.5.3.2}\protected@file@percent }
\newlabel{the-model}{{5.3.2}{38}{The Model}{subsection.5.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Loss Function and Optimization}{40}{subsection.5.3.3}\protected@file@percent }
\newlabel{loss-function-and-optimization}{{5.3.3}{40}{Loss Function and Optimization}{subsection.5.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.4}Assumptions}{40}{subsection.5.3.4}\protected@file@percent }
\newlabel{assumptions}{{5.3.4}{40}{Assumptions}{subsection.5.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.5}Advantages and Disadvantages}{41}{subsection.5.3.5}\protected@file@percent }
\newlabel{advantages-and-disadvantages-1}{{5.3.5}{41}{Advantages and Disadvantages}{subsection.5.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.6}Applications}{41}{subsection.5.3.6}\protected@file@percent }
\newlabel{applications-2}{{5.3.6}{41}{Applications}{subsection.5.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Logistic Regression}{41}{section.5.4}\protected@file@percent }
\newlabel{logistic-regression}{{5.4}{41}{Logistic Regression}{section.5.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Overview}{41}{subsection.5.4.1}\protected@file@percent }
\newlabel{overview-2}{{5.4.1}{41}{Overview}{subsection.5.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}The Logistic Function}{41}{subsection.5.4.2}\protected@file@percent }
\newlabel{the-logistic-function}{{5.4.2}{41}{The Logistic Function}{subsection.5.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Types of Logistic Regression}{45}{subsection.5.4.3}\protected@file@percent }
\newlabel{types-of-logistic-regression}{{5.4.3}{45}{Types of Logistic Regression}{subsection.5.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}Maximum Likelihood Estimation}{45}{subsection.5.4.4}\protected@file@percent }
\newlabel{maximum-likelihood-estimation}{{5.4.4}{45}{Maximum Likelihood Estimation}{subsection.5.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.5}Evaluation Metrics}{45}{subsection.5.4.5}\protected@file@percent }
\newlabel{evaluation-metrics}{{5.4.5}{45}{Evaluation Metrics}{subsection.5.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.6}Regularization}{46}{subsection.5.4.6}\protected@file@percent }
\newlabel{regularization}{{5.4.6}{46}{Regularization}{subsection.5.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.7}Advantages and Disadvantages}{47}{subsection.5.4.7}\protected@file@percent }
\newlabel{advantages-and-disadvantages-2}{{5.4.7}{47}{Advantages and Disadvantages}{subsection.5.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.8}Applications}{47}{subsection.5.4.8}\protected@file@percent }
\newlabel{applications-3}{{5.4.8}{47}{Applications}{subsection.5.4.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Comparison of Algorithms}{48}{section.5.5}\protected@file@percent }
\newlabel{comparison-of-algorithms}{{5.5}{48}{Comparison of Algorithms}{section.5.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Summary}{49}{section.5.6}\protected@file@percent }
\newlabel{summary}{{5.6}{49}{Summary}{section.5.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Choosing the Right Algorithm}{50}{subsection.5.6.1}\protected@file@percent }
\newlabel{choosing-the-right-algorithm}{{5.6.1}{50}{Choosing the Right Algorithm}{subsection.5.6.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Dimensionality Reduction Methods}{51}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{dimensionality-reduction-methods}{{6}{51}{Dimensionality Reduction Methods}{chapter.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces }}{51}{figure.caption.3}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig-libraries}{{6.1}{51}{}{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Why Reduce Dimensionality?}{51}{section.6.1}\protected@file@percent }
\newlabel{why-reduce-dimensionality}{{6.1}{51}{Why Reduce Dimensionality?}{section.6.1}{}}
\gdef \LT@ii {\LT@entry 
    {3}{11.47502pt}\LT@entry 
    {1}{95.39519pt}\LT@entry 
    {1}{92.96428pt}\LT@entry 
    {1}{95.64705pt}\LT@entry 
    {1}{93.21614pt}\LT@entry 
    {1}{38.65291pt}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Dataset Example: Iris}{52}{section.6.2}\protected@file@percent }
\newlabel{dataset-example-iris}{{6.2}{52}{Dataset Example: Iris}{section.6.2}{}}
\newlabel{fig-iris-data}{{6.2}{52}{Dataset Example: Iris}{section*.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Approaches to Dimensionality Reduction}{52}{section.6.3}\protected@file@percent }
\newlabel{approaches-to-dimensionality-reduction}{{6.3}{52}{Approaches to Dimensionality Reduction}{section.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Unsupervised Methods}{53}{subsection.6.3.1}\protected@file@percent }
\newlabel{unsupervised-methods}{{6.3.1}{53}{Unsupervised Methods}{subsection.6.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1.1}Principal Component Analysis (PCA)}{53}{subsubsection.6.3.1.1}\protected@file@percent }
\newlabel{principal-component-analysis-pca}{{6.3.1.1}{53}{Principal Component Analysis (PCA)}{subsubsection.6.3.1.1}{}}
\newlabel{fig-pca-iris-1}{{6.2a}{55}{PCA visualization of the Iris dataset}{figure.caption.5}{}}
\newlabel{sub@fig-pca-iris-1}{{a}{55}{PCA visualization of the Iris dataset}{figure.caption.5}{}}
\newlabel{fig-pca-iris-2}{{6.2b}{55}{}{figure.caption.5}{}}
\newlabel{sub@fig-pca-iris-2}{{b}{55}{}{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces }}{55}{figure.caption.5}\protected@file@percent }
\newlabel{fig-pca-iris}{{6.2}{55}{}{figure.caption.5}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.3.1.1.1}Key Concepts of PCA}{56}{paragraph.6.3.1.1.1}\protected@file@percent }
\newlabel{key-concepts-of-pca}{{6.3.1.1.1}{56}{Key Concepts of PCA}{paragraph.6.3.1.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces PCA components and their relationship to original features}}{57}{figure.caption.6}\protected@file@percent }
\newlabel{fig-pca-components}{{6.3}{57}{PCA components and their relationship to original features}{figure.caption.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.1.2}Other Unsupervised Methods}{57}{subsubsection.6.3.1.2}\protected@file@percent }
\newlabel{other-unsupervised-methods}{{6.3.1.2}{57}{Other Unsupervised Methods}{subsubsection.6.3.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Supervised Methods}{57}{subsection.6.3.2}\protected@file@percent }
\newlabel{supervised-methods}{{6.3.2}{57}{Supervised Methods}{subsection.6.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2.1}Linear Discriminant Analysis (LDA)}{58}{subsubsection.6.3.2.1}\protected@file@percent }
\newlabel{linear-discriminant-analysis-lda}{{6.3.2.1}{58}{Linear Discriminant Analysis (LDA)}{subsubsection.6.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces LDA visualization of the Iris dataset}}{59}{figure.caption.7}\protected@file@percent }
\newlabel{fig-lda-iris}{{6.4}{59}{LDA visualization of the Iris dataset}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Advanced PCA Implementations}{59}{section.6.4}\protected@file@percent }
\newlabel{advanced-pca-implementations}{{6.4}{59}{Advanced PCA Implementations}{section.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Kernel PCA}{59}{subsection.6.4.1}\protected@file@percent }
\newlabel{kernel-pca}{{6.4.1}{59}{Kernel PCA}{subsection.6.4.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Comparison of PCA and Kernel PCA}}{60}{figure.caption.8}\protected@file@percent }
\newlabel{fig-kernel-pca}{{6.5}{60}{Comparison of PCA and Kernel PCA}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.2}Incremental PCA}{60}{subsection.6.4.2}\protected@file@percent }
\newlabel{incremental-pca}{{6.4.2}{60}{Incremental PCA}{subsection.6.4.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces }}{62}{figure.caption.9}\protected@file@percent }
\newlabel{fig-incremental-pca}{{6.6}{62}{}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Visualizing High-Dimensional Data with t-SNE}{62}{section.6.5}\protected@file@percent }
\newlabel{visualizing-high-dimensional-data-with-t-sne}{{6.5}{62}{Visualizing High-Dimensional Data with t-SNE}{section.6.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces t-SNE visualization of the Iris dataset}}{63}{figure.caption.10}\protected@file@percent }
\newlabel{fig-tsne}{{6.7}{63}{t-SNE visualization of the Iris dataset}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Real-World Application: MNIST Dataset}{63}{section.6.6}\protected@file@percent }
\newlabel{real-world-application-mnist-dataset}{{6.6}{63}{Real-World Application: MNIST Dataset}{section.6.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Interactive 3D Visualization with Plotly}{63}{section.6.7}\protected@file@percent }
\newlabel{interactive-3d-visualization-with-plotly}{{6.7}{63}{Interactive 3D Visualization with Plotly}{section.6.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces }}{64}{figure.caption.11}\protected@file@percent }
\newlabel{fig-mnist}{{6.8}{64}{}{figure.caption.11}{}}
\newlabel{fig-3d-pca-1}{{6.9a}{65}{3D PCA visualization of the Iris dataset}{figure.caption.12}{}}
\newlabel{sub@fig-3d-pca-1}{{a}{65}{3D PCA visualization of the Iris dataset}{figure.caption.12}{}}
\newlabel{fig-3d-pca-2}{{6.9b}{65}{}{figure.caption.12}{}}
\newlabel{sub@fig-3d-pca-2}{{b}{65}{}{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces }}{65}{figure.caption.12}\protected@file@percent }
\newlabel{fig-3d-pca}{{6.9}{65}{}{figure.caption.12}{}}
\gdef \LT@iii {\LT@entry 
    {1}{107.29231pt}\LT@entry 
    {1}{113.29231pt}\LT@entry 
    {1}{118.9207pt}\LT@entry 
    {1}{107.29231pt}}
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Choosing the Right Dimensionality Reduction Technique}{66}{section.6.8}\protected@file@percent }
\newlabel{choosing-the-right-dimensionality-reduction-technique}{{6.8}{66}{Choosing the Right Dimensionality Reduction Technique}{section.6.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Singular Value Decomposition (SVD)}{66}{section.6.9}\protected@file@percent }
\newlabel{singular-value-decomposition-svd}{{6.9}{66}{Singular Value Decomposition (SVD)}{section.6.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces }}{66}{figure.caption.13}\protected@file@percent }
\newlabel{fig-svd-libraries}{{6.10}{66}{}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.1}Mathematical Foundation}{66}{subsection.6.9.1}\protected@file@percent }
\newlabel{mathematical-foundation}{{6.9.1}{66}{Mathematical Foundation}{subsection.6.9.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.2}Basic SVD Example}{67}{subsection.6.9.2}\protected@file@percent }
\newlabel{basic-svd-example}{{6.9.2}{67}{Basic SVD Example}{subsection.6.9.2}{}}
\newlabel{fig-svd-iris-1}{{6.11a}{69}{SVD applied to the Iris dataset}{figure.caption.14}{}}
\newlabel{sub@fig-svd-iris-1}{{a}{69}{SVD applied to the Iris dataset}{figure.caption.14}{}}
\newlabel{fig-svd-iris-2}{{6.11b}{69}{}{figure.caption.14}{}}
\newlabel{sub@fig-svd-iris-2}{{b}{69}{}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces }}{69}{figure.caption.14}\protected@file@percent }
\newlabel{fig-svd-iris}{{6.11}{69}{}{figure.caption.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.3}Relationship Between SVD and PCA}{70}{subsection.6.9.3}\protected@file@percent }
\newlabel{relationship-between-svd-and-pca}{{6.9.3}{70}{Relationship Between SVD and PCA}{subsection.6.9.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces Comparison of SVD and PCA projections}}{71}{figure.caption.15}\protected@file@percent }
\newlabel{fig-svd-pca-comparison}{{6.12}{71}{Comparison of SVD and PCA projections}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.4}Low-Rank Approximation}{71}{subsection.6.9.4}\protected@file@percent }
\newlabel{low-rank-approximation}{{6.9.4}{71}{Low-Rank Approximation}{subsection.6.9.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces Low-rank approximation of a matrix}}{73}{figure.caption.16}\protected@file@percent }
\newlabel{fig-svd-low-rank}{{6.13}{73}{Low-rank approximation of a matrix}{figure.caption.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.5}SVD for Image Compression}{73}{subsection.6.9.5}\protected@file@percent }
\newlabel{svd-for-image-compression}{{6.9.5}{73}{SVD for Image Compression}{subsection.6.9.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.6}Applications of SVD}{73}{subsection.6.9.6}\protected@file@percent }
\newlabel{applications-of-svd}{{6.9.6}{73}{Applications of SVD}{subsection.6.9.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.9.6.1}1. Recommendation Systems}{73}{subsubsection.6.9.6.1}\protected@file@percent }
\newlabel{recommendation-systems}{{6.9.6.1}{73}{1. Recommendation Systems}{subsubsection.6.9.6.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.9.6.2}2. Latent Semantic Analysis (LSA) for Text Mining}{73}{subsubsection.6.9.6.2}\protected@file@percent }
\newlabel{latent-semantic-analysis-lsa-for-text-mining}{{6.9.6.2}{73}{2. Latent Semantic Analysis (LSA) for Text Mining}{subsubsection.6.9.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.9.7}Truncated SVD vs.~PCA}{73}{subsection.6.9.7}\protected@file@percent }
\newlabel{truncated-svd-vs.-pca}{{6.9.7}{73}{Truncated SVD vs.~PCA}{subsection.6.9.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces }}{74}{figure.caption.17}\protected@file@percent }
\newlabel{fig-image-compression}{{6.14}{74}{}{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.15}{\ignorespaces }}{75}{figure.caption.18}\protected@file@percent }
\newlabel{fig-recommendation}{{6.15}{75}{}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.16}{\ignorespaces }}{76}{figure.caption.19}\protected@file@percent }
\newlabel{fig-lsa}{{6.16}{76}{}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.17}{\ignorespaces Comparison of Truncated SVD and PCA}}{78}{figure.caption.20}\protected@file@percent }
\newlabel{fig-truncated-svd}{{6.17}{78}{Comparison of Truncated SVD and PCA}{figure.caption.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.10}No\# Advantages and Limitations of SVD}{78}{section.6.10}\protected@file@percent }
\newlabel{no-advantages-and-limitations-of-svd}{{6.10}{78}{No\# Advantages and Limitations of SVD}{section.6.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.10.0.1}Advantages}{78}{subsubsection.6.10.0.1}\protected@file@percent }
\newlabel{advantages-1}{{6.10.0.1}{78}{Advantages}{subsubsection.6.10.0.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.10.0.2}Limitations}{78}{subsubsection.6.10.0.2}\protected@file@percent }
\newlabel{limitations}{{6.10.0.2}{78}{Limitations}{subsubsection.6.10.0.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.11}Conclusion}{79}{section.6.11}\protected@file@percent }
\newlabel{conclusion}{{6.11}{79}{Conclusion}{section.6.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.12}References}{79}{section.6.12}\protected@file@percent }
\newlabel{references}{{6.12}{79}{References}{section.6.12}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Tree-Based Models and Ensemble Learning}{80}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{tree-based-models-and-ensemble-learning}{{7}{80}{Tree-Based Models and Ensemble Learning}{chapter.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Decision Trees}{80}{section.7.1}\protected@file@percent }
\newlabel{decision-trees}{{7.1}{80}{Decision Trees}{section.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Key Features}{80}{subsection.7.1.1}\protected@file@percent }
\newlabel{key-features}{{7.1.1}{80}{Key Features}{subsection.7.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}Core Concepts}{80}{subsection.7.1.2}\protected@file@percent }
\newlabel{core-concepts}{{7.1.2}{80}{Core Concepts}{subsection.7.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.3}Decision Boundaries}{80}{subsection.7.1.3}\protected@file@percent }
\newlabel{decision-boundaries}{{7.1.3}{80}{Decision Boundaries}{subsection.7.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.4}Representation}{82}{subsection.7.1.4}\protected@file@percent }
\newlabel{representation}{{7.1.4}{82}{Representation}{subsection.7.1.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.5}When to Use Decision Trees}{82}{subsection.7.1.5}\protected@file@percent }
\newlabel{when-to-use-decision-trees}{{7.1.5}{82}{When to Use Decision Trees}{subsection.7.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.6}Classification Process}{83}{subsection.7.1.6}\protected@file@percent }
\newlabel{classification-process}{{7.1.6}{83}{Classification Process}{subsection.7.1.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.7}Algorithmic Approaches}{83}{subsection.7.1.7}\protected@file@percent }
\newlabel{algorithmic-approaches}{{7.1.7}{83}{Algorithmic Approaches}{subsection.7.1.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.8}The CART Algorithm}{83}{subsection.7.1.8}\protected@file@percent }
\newlabel{the-cart-algorithm}{{7.1.8}{83}{The CART Algorithm}{subsection.7.1.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.9}Training a Decision Tree}{83}{subsection.7.1.9}\protected@file@percent }
\newlabel{training-a-decision-tree}{{7.1.9}{83}{Training a Decision Tree}{subsection.7.1.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.9.1}Impurity Measures}{85}{subsubsection.7.1.9.1}\protected@file@percent }
\newlabel{impurity-measures}{{7.1.9.1}{85}{Impurity Measures}{subsubsection.7.1.9.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {7.1.9.1.1}Entropy}{85}{paragraph.7.1.9.1.1}\protected@file@percent }
\newlabel{entropy}{{7.1.9.1.1}{85}{Entropy}{paragraph.7.1.9.1.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {7.1.9.1.2}Information Gain}{85}{paragraph.7.1.9.1.2}\protected@file@percent }
\newlabel{information-gain}{{7.1.9.1.2}{85}{Information Gain}{paragraph.7.1.9.1.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {7.1.9.1.3}Gini Impurity}{85}{paragraph.7.1.9.1.3}\protected@file@percent }
\newlabel{gini-impurity}{{7.1.9.1.3}{85}{Gini Impurity}{paragraph.7.1.9.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.10}Pruning Techniques}{86}{subsection.7.1.10}\protected@file@percent }
\newlabel{pruning-techniques}{{7.1.10}{86}{Pruning Techniques}{subsection.7.1.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.10.1}Pre-pruning (Early Stopping)}{86}{subsubsection.7.1.10.1}\protected@file@percent }
\newlabel{pre-pruning-early-stopping}{{7.1.10.1}{86}{Pre-pruning (Early Stopping)}{subsubsection.7.1.10.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.10.2}Post-pruning}{86}{subsubsection.7.1.10.2}\protected@file@percent }
\newlabel{post-pruning}{{7.1.10.2}{86}{Post-pruning}{subsubsection.7.1.10.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.11}Handling Categorical and Continuous Features}{86}{subsection.7.1.11}\protected@file@percent }
\newlabel{handling-categorical-and-continuous-features}{{7.1.11}{86}{Handling Categorical and Continuous Features}{subsection.7.1.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.12}Advantages and Limitations}{87}{subsection.7.1.12}\protected@file@percent }
\newlabel{advantages-and-limitations}{{7.1.12}{87}{Advantages and Limitations}{subsection.7.1.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.12.1}Advantages}{87}{subsubsection.7.1.12.1}\protected@file@percent }
\newlabel{advantages-2}{{7.1.12.1}{87}{Advantages}{subsubsection.7.1.12.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.12.2}Limitations}{87}{subsubsection.7.1.12.2}\protected@file@percent }
\newlabel{limitations-1}{{7.1.12.2}{87}{Limitations}{subsubsection.7.1.12.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}Ensemble Methods}{87}{section.7.2}\protected@file@percent }
\newlabel{ensemble-methods}{{7.2}{87}{Ensemble Methods}{section.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.1}Core Principles}{87}{subsection.7.2.1}\protected@file@percent }
\newlabel{core-principles}{{7.2.1}{87}{Core Principles}{subsection.7.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.2}The Bias-Variance Tradeoff}{87}{subsection.7.2.2}\protected@file@percent }
\newlabel{the-bias-variance-tradeoff}{{7.2.2}{87}{The Bias-Variance Tradeoff}{subsection.7.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.3}Types of Ensemble Learning}{88}{subsection.7.2.3}\protected@file@percent }
\newlabel{types-of-ensemble-learning}{{7.2.3}{88}{Types of Ensemble Learning}{subsection.7.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2.4}Theoretical Foundations}{89}{subsection.7.2.4}\protected@file@percent }
\newlabel{theoretical-foundations}{{7.2.4}{89}{Theoretical Foundations}{subsection.7.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}Random Forests}{89}{section.7.3}\protected@file@percent }
\newlabel{random-forests}{{7.3}{89}{Random Forests}{section.7.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.1}Core Concepts}{90}{subsection.7.3.1}\protected@file@percent }
\newlabel{core-concepts-1}{{7.3.1}{90}{Core Concepts}{subsection.7.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.2}Random Forest Algorithm}{90}{subsection.7.3.2}\protected@file@percent }
\newlabel{random-forest-algorithm}{{7.3.2}{90}{Random Forest Algorithm}{subsection.7.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.3}How Random Forest Works}{91}{subsection.7.3.3}\protected@file@percent }
\newlabel{how-random-forest-works}{{7.3.3}{91}{How Random Forest Works}{subsection.7.3.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.4}Key Features of Random Forests}{91}{subsection.7.3.4}\protected@file@percent }
\newlabel{key-features-of-random-forests}{{7.3.4}{91}{Key Features of Random Forests}{subsection.7.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.5}Mathematical Intuition}{92}{subsection.7.3.5}\protected@file@percent }
\newlabel{mathematical-intuition}{{7.3.5}{92}{Mathematical Intuition}{subsection.7.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.6}Out-of-Bag (OOB) Error Estimation}{92}{subsection.7.3.6}\protected@file@percent }
\newlabel{out-of-bag-oob-error-estimation}{{7.3.6}{92}{Out-of-Bag (OOB) Error Estimation}{subsection.7.3.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.7}Feature Importance}{92}{subsection.7.3.7}\protected@file@percent }
\newlabel{feature-importance}{{7.3.7}{92}{Feature Importance}{subsection.7.3.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.8}Proximity Analysis}{92}{subsection.7.3.8}\protected@file@percent }
\newlabel{proximity-analysis}{{7.3.8}{92}{Proximity Analysis}{subsection.7.3.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.9}Hyperparameters}{93}{subsection.7.3.9}\protected@file@percent }
\newlabel{hyperparameters}{{7.3.9}{93}{Hyperparameters}{subsection.7.3.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3.10}Advantages and Limitations}{93}{subsection.7.3.10}\protected@file@percent }
\newlabel{advantages-and-limitations-1}{{7.3.10}{93}{Advantages and Limitations}{subsection.7.3.10}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.10.1}Advantages}{93}{subsubsection.7.3.10.1}\protected@file@percent }
\newlabel{advantages-3}{{7.3.10.1}{93}{Advantages}{subsubsection.7.3.10.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.3.10.2}Limitations}{93}{subsubsection.7.3.10.2}\protected@file@percent }
\newlabel{limitations-2}{{7.3.10.2}{93}{Limitations}{subsubsection.7.3.10.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}Gradient Boosting}{93}{section.7.4}\protected@file@percent }
\newlabel{gradient-boosting}{{7.4}{93}{Gradient Boosting}{section.7.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.1}Core Concepts}{93}{subsection.7.4.1}\protected@file@percent }
\newlabel{core-concepts-2}{{7.4.1}{93}{Core Concepts}{subsection.7.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.2}Gradient Boosting Algorithm}{94}{subsection.7.4.2}\protected@file@percent }
\newlabel{gradient-boosting-algorithm}{{7.4.2}{94}{Gradient Boosting Algorithm}{subsection.7.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.3}How Gradient Boosting Works}{96}{subsection.7.4.3}\protected@file@percent }
\newlabel{how-gradient-boosting-works}{{7.4.3}{96}{How Gradient Boosting Works}{subsection.7.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.4}Mathematical Formulation}{96}{subsection.7.4.4}\protected@file@percent }
\newlabel{mathematical-formulation}{{7.4.4}{96}{Mathematical Formulation}{subsection.7.4.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.5}Loss Functions}{97}{subsection.7.4.5}\protected@file@percent }
\newlabel{loss-functions}{{7.4.5}{97}{Loss Functions}{subsection.7.4.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.6}Types of Gradient Boosting}{97}{subsection.7.4.6}\protected@file@percent }
\newlabel{types-of-gradient-boosting}{{7.4.6}{97}{Types of Gradient Boosting}{subsection.7.4.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.7}Regularization Techniques}{97}{subsection.7.4.7}\protected@file@percent }
\newlabel{regularization-techniques}{{7.4.7}{97}{Regularization Techniques}{subsection.7.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.8}Key Hyperparameters}{97}{subsection.7.4.8}\protected@file@percent }
\newlabel{key-hyperparameters}{{7.4.8}{97}{Key Hyperparameters}{subsection.7.4.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.4.9}Advantages and Limitations}{98}{subsection.7.4.9}\protected@file@percent }
\newlabel{advantages-and-limitations-2}{{7.4.9}{98}{Advantages and Limitations}{subsection.7.4.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.9.1}Advantages}{98}{subsubsection.7.4.9.1}\protected@file@percent }
\newlabel{advantages-4}{{7.4.9.1}{98}{Advantages}{subsubsection.7.4.9.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.4.9.2}Limitations}{98}{subsubsection.7.4.9.2}\protected@file@percent }
\newlabel{limitations-3}{{7.4.9.2}{98}{Limitations}{subsubsection.7.4.9.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}Comparing Ensemble Methods}{98}{section.7.5}\protected@file@percent }
\newlabel{comparing-ensemble-methods}{{7.5}{98}{Comparing Ensemble Methods}{section.7.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}Bagging vs.~Boosting}{100}{subsection.7.5.1}\protected@file@percent }
\newlabel{bagging-vs.-boosting}{{7.5.1}{100}{Bagging vs.~Boosting}{subsection.7.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1.1}Bagging (Random Forest)}{100}{subsubsection.7.5.1.1}\protected@file@percent }
\newlabel{bagging-random-forest}{{7.5.1.1}{100}{Bagging (Random Forest)}{subsubsection.7.5.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.5.1.2}Boosting (Gradient Boosting)}{100}{subsubsection.7.5.1.2}\protected@file@percent }
\newlabel{boosting-gradient-boosting}{{7.5.1.2}{100}{Boosting (Gradient Boosting)}{subsubsection.7.5.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}Stacking}{100}{subsection.7.5.2}\protected@file@percent }
\newlabel{stacking}{{7.5.2}{100}{Stacking}{subsection.7.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.3}Choosing the Right Ensemble Method}{100}{subsection.7.5.3}\protected@file@percent }
\newlabel{choosing-the-right-ensemble-method}{{7.5.3}{100}{Choosing the Right Ensemble Method}{subsection.7.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.4}Practical Considerations}{101}{subsection.7.5.4}\protected@file@percent }
\newlabel{practical-considerations}{{7.5.4}{101}{Practical Considerations}{subsection.7.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}Conclusion}{101}{section.7.6}\protected@file@percent }
\newlabel{conclusion-1}{{7.6}{101}{Conclusion}{section.7.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.1}Key Takeaways}{101}{subsection.7.6.1}\protected@file@percent }
\newlabel{key-takeaways}{{7.6.1}{101}{Key Takeaways}{subsection.7.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.2}Further Research Directions}{103}{subsection.7.6.2}\protected@file@percent }
\newlabel{further-research-directions}{{7.6.2}{103}{Further Research Directions}{subsection.7.6.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Support Vector Machines and Model Evaluation}{104}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{support-vector-machines-and-model-evaluation}{{8}{104}{Support Vector Machines and Model Evaluation}{chapter.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Support Vector Machine (SVM)}{104}{section.8.1}\protected@file@percent }
\newlabel{support-vector-machine-svm}{{8.1}{104}{Support Vector Machine (SVM)}{section.8.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}Key Concepts}{104}{subsection.8.1.1}\protected@file@percent }
\newlabel{key-concepts}{{8.1.1}{104}{Key Concepts}{subsection.8.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.1.1}Conceptual Understanding}{104}{subsubsection.8.1.1.1}\protected@file@percent }
\newlabel{conceptual-understanding}{{8.1.1.1}{104}{Conceptual Understanding}{subsubsection.8.1.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}The Dual Problem and Support Vectors}{106}{subsection.8.1.2}\protected@file@percent }
\newlabel{the-dual-problem-and-support-vectors}{{8.1.2}{106}{The Dual Problem and Support Vectors}{subsection.8.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.3}SVM for Classification and Regression}{107}{subsection.8.1.3}\protected@file@percent }
\newlabel{svm-for-classification-and-regression}{{8.1.3}{107}{SVM for Classification and Regression}{subsection.8.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.3.1}SVM Classification (SVC)}{107}{subsubsection.8.1.3.1}\protected@file@percent }
\newlabel{svm-classification-svc}{{8.1.3.1}{107}{SVM Classification (SVC)}{subsubsection.8.1.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.3.2}SVM Regression (SVR)}{107}{subsubsection.8.1.3.2}\protected@file@percent }
\newlabel{svm-regression-svr}{{8.1.3.2}{107}{SVM Regression (SVR)}{subsubsection.8.1.3.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.4}Non-linear Classification with Kernels}{107}{subsection.8.1.4}\protected@file@percent }
\newlabel{non-linear-classification-with-kernels}{{8.1.4}{107}{Non-linear Classification with Kernels}{subsection.8.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.4.1}Understanding the Kernel Trick}{108}{subsubsection.8.1.4.1}\protected@file@percent }
\newlabel{understanding-the-kernel-trick}{{8.1.4.1}{108}{Understanding the Kernel Trick}{subsubsection.8.1.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.4.2}Common Kernel Types}{109}{subsubsection.8.1.4.2}\protected@file@percent }
\newlabel{common-kernel-types}{{8.1.4.2}{109}{Common Kernel Types}{subsubsection.8.1.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.5}SVM Parameters}{109}{subsection.8.1.5}\protected@file@percent }
\newlabel{svm-parameters}{{8.1.5}{109}{SVM Parameters}{subsection.8.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.5.1}The Role of C (Regularization Parameter)}{109}{subsubsection.8.1.5.1}\protected@file@percent }
\newlabel{the-role-of-c-regularization-parameter}{{8.1.5.1}{109}{The Role of C (Regularization Parameter)}{subsubsection.8.1.5.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.5.2}The Role of Gamma (Kernel Coefficient)}{111}{subsubsection.8.1.5.2}\protected@file@percent }
\newlabel{the-role-of-gamma-kernel-coefficient}{{8.1.5.2}{111}{The Role of Gamma (Kernel Coefficient)}{subsubsection.8.1.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.6}Strengths and Weaknesses of SVM}{112}{subsection.8.1.6}\protected@file@percent }
\newlabel{strengths-and-weaknesses-of-svm}{{8.1.6}{112}{Strengths and Weaknesses of SVM}{subsection.8.1.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.6.1}Strengths}{112}{subsubsection.8.1.6.1}\protected@file@percent }
\newlabel{strengths}{{8.1.6.1}{112}{Strengths}{subsubsection.8.1.6.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.1.6.2}Weaknesses}{112}{subsubsection.8.1.6.2}\protected@file@percent }
\newlabel{weaknesses}{{8.1.6.2}{112}{Weaknesses}{subsubsection.8.1.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.7}Practical Example: Full Iris Dataset}{112}{subsection.8.1.7}\protected@file@percent }
\newlabel{practical-example-full-iris-dataset}{{8.1.7}{112}{Practical Example: Full Iris Dataset}{subsection.8.1.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Performance Metrics in Machine Learning}{113}{section.8.2}\protected@file@percent }
\newlabel{performance-metrics-in-machine-learning}{{8.2}{113}{Performance Metrics in Machine Learning}{section.8.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.1}Classification Metrics}{114}{subsection.8.2.1}\protected@file@percent }
\newlabel{classification-metrics}{{8.2.1}{114}{Classification Metrics}{subsection.8.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1.1}1. Accuracy}{119}{subsubsection.8.2.1.1}\protected@file@percent }
\newlabel{accuracy}{{8.2.1.1}{119}{1. Accuracy}{subsubsection.8.2.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1.2}2. Precision}{119}{subsubsection.8.2.1.2}\protected@file@percent }
\newlabel{precision}{{8.2.1.2}{119}{2. Precision}{subsubsection.8.2.1.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1.3}3. Recall (Sensitivity or True Positive Rate)}{120}{subsubsection.8.2.1.3}\protected@file@percent }
\newlabel{recall-sensitivity-or-true-positive-rate}{{8.2.1.3}{120}{3. Recall (Sensitivity or True Positive Rate)}{subsubsection.8.2.1.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1.4}4. F1 Score}{120}{subsubsection.8.2.1.4}\protected@file@percent }
\newlabel{f1-score}{{8.2.1.4}{120}{4. F1 Score}{subsubsection.8.2.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.1.5}5. Confusion Matrix}{120}{subsubsection.8.2.1.5}\protected@file@percent }
\newlabel{confusion-matrix}{{8.2.1.5}{120}{5. Confusion Matrix}{subsubsection.8.2.1.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.2}Understanding ROC and Precision-Recall Curves}{120}{subsection.8.2.2}\protected@file@percent }
\newlabel{understanding-roc-and-precision-recall-curves}{{8.2.2}{120}{Understanding ROC and Precision-Recall Curves}{subsection.8.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2.1}ROC Curve (Receiver Operating Characteristic)}{120}{subsubsection.8.2.2.1}\protected@file@percent }
\newlabel{roc-curve-receiver-operating-characteristic}{{8.2.2.1}{120}{ROC Curve (Receiver Operating Characteristic)}{subsubsection.8.2.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2.2}ROC Curve Components}{122}{subsubsection.8.2.2.2}\protected@file@percent }
\newlabel{roc-curve-components}{{8.2.2.2}{122}{ROC Curve Components}{subsubsection.8.2.2.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2.3}AUC (Area Under the ROC Curve)}{123}{subsubsection.8.2.2.3}\protected@file@percent }
\newlabel{auc-area-under-the-roc-curve}{{8.2.2.3}{123}{AUC (Area Under the ROC Curve)}{subsubsection.8.2.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2.4}Precision-Recall Curve}{123}{subsubsection.8.2.2.4}\protected@file@percent }
\newlabel{precision-recall-curve}{{8.2.2.4}{123}{Precision-Recall Curve}{subsubsection.8.2.2.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.2.5}When to Use ROC vs.~PR Curves}{123}{subsubsection.8.2.2.5}\protected@file@percent }
\newlabel{when-to-use-roc-vs.-pr-curves}{{8.2.2.5}{123}{When to Use ROC vs.~PR Curves}{subsubsection.8.2.2.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.3}Regression Metrics}{123}{subsection.8.2.3}\protected@file@percent }
\newlabel{regression-metrics}{{8.2.3}{123}{Regression Metrics}{subsection.8.2.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.3.1}1. Mean Absolute Error (MAE)}{126}{subsubsection.8.2.3.1}\protected@file@percent }
\newlabel{mean-absolute-error-mae}{{8.2.3.1}{126}{1. Mean Absolute Error (MAE)}{subsubsection.8.2.3.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.3.2}2. Mean Squared Error (MSE)}{126}{subsubsection.8.2.3.2}\protected@file@percent }
\newlabel{mean-squared-error-mse}{{8.2.3.2}{126}{2. Mean Squared Error (MSE)}{subsubsection.8.2.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.3.3}3. Root Mean Squared Error (RMSE)}{126}{subsubsection.8.2.3.3}\protected@file@percent }
\newlabel{root-mean-squared-error-rmse}{{8.2.3.3}{126}{3. Root Mean Squared Error (RMSE)}{subsubsection.8.2.3.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.3.4}4. R-Squared (R²)}{127}{subsubsection.8.2.3.4}\protected@file@percent }
\newlabel{r-squared-ruxb2}{{8.2.3.4}{127}{4. R-Squared (R²)}{subsubsection.8.2.3.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {8.2.3.5}5. Adjusted R-Squared}{127}{subsubsection.8.2.3.5}\protected@file@percent }
\newlabel{adjusted-r-squared}{{8.2.3.5}{127}{5. Adjusted R-Squared}{subsubsection.8.2.3.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2.4}Understanding Residual Plots}{127}{subsection.8.2.4}\protected@file@percent }
\newlabel{understanding-residual-plots}{{8.2.4}{127}{Understanding Residual Plots}{subsection.8.2.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}Model Fit Issues}{127}{section.8.3}\protected@file@percent }
\newlabel{model-fit-issues}{{8.3}{127}{Model Fit Issues}{section.8.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3.1}Underfitting vs.~Overfitting}{127}{subsection.8.3.1}\protected@file@percent }
\newlabel{underfitting-vs.-overfitting}{{8.3.1}{127}{Underfitting vs.~Overfitting}{subsection.8.3.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Demonstrate underfitting vs.~overfitting with polynomial regression}{128}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{demonstrate-underfitting-vs.-overfitting-with-polynomial-regression}{{9}{128}{Demonstrate underfitting vs.~overfitting with polynomial regression}{chapter.9}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Generate synthetic data}{129}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{generate-synthetic-data}{{10}{129}{Generate synthetic data}{chapter.10}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {11}Split into train and test}{130}{chapter.11}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{split-into-train-and-test}{{11}{130}{Split into train and test}{chapter.11}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {12}Create polynomials of different degrees}{131}{chapter.12}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{create-polynomials-of-different-degrees}{{12}{131}{Create polynomials of different degrees}{chapter.12}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {13}Outlier Detection and Recommendation Systems}{132}{chapter.13}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{outlier-detection-and-recommendation-systems}{{13}{132}{Outlier Detection and Recommendation Systems}{chapter.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.1}Graphical Outlier Detection}{132}{section.13.1}\protected@file@percent }
\newlabel{graphical-outlier-detection}{{13.1}{132}{Graphical Outlier Detection}{section.13.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.1.1}Quartiles and the Boxplot Method}{134}{subsection.13.1.1}\protected@file@percent }
\newlabel{quartiles-and-the-boxplot-method}{{13.1.1}{134}{Quartiles and the Boxplot Method}{subsection.13.1.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.2}Cluster-Based Outlier Detection}{135}{section.13.2}\protected@file@percent }
\newlabel{cluster-based-outlier-detection}{{13.2}{135}{Cluster-Based Outlier Detection}{section.13.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.3}Distance-Based Outlier Detection}{137}{section.13.3}\protected@file@percent }
\newlabel{distance-based-outlier-detection}{{13.3}{137}{Distance-Based Outlier Detection}{section.13.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.1}Global Distance-Based Detection (KNN)}{137}{subsection.13.3.1}\protected@file@percent }
\newlabel{global-distance-based-detection-knn}{{13.3.1}{137}{Global Distance-Based Detection (KNN)}{subsection.13.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {13.3.2}Local Distance-Based Detection}{138}{subsection.13.3.2}\protected@file@percent }
\newlabel{local-distance-based-detection}{{13.3.2}{138}{Local Distance-Based Detection}{subsection.13.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.4}Tree-Based Outlier Detection: Isolation Forests}{139}{section.13.4}\protected@file@percent }
\newlabel{tree-based-outlier-detection-isolation-forests}{{13.4}{139}{Tree-Based Outlier Detection: Isolation Forests}{section.13.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {13.5}Challenges in Unsupervised Outlier Detection}{142}{section.13.5}\protected@file@percent }
\newlabel{challenges-in-unsupervised-outlier-detection}{{13.5}{142}{Challenges in Unsupervised Outlier Detection}{section.13.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {14}Recommender Systems}{143}{chapter.14}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{recommender-systems}{{14}{143}{Recommender Systems}{chapter.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.1}Recommendation Scenarios}{143}{section.14.1}\protected@file@percent }
\newlabel{recommendation-scenarios}{{14.1}{143}{Recommendation Scenarios}{section.14.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.2}Types of Recommender Systems}{143}{section.14.2}\protected@file@percent }
\newlabel{types-of-recommender-systems}{{14.2}{143}{Types of Recommender Systems}{section.14.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.1}1. Content-Based Filtering}{143}{subsection.14.2.1}\protected@file@percent }
\newlabel{content-based-filtering}{{14.2.1}{143}{1. Content-Based Filtering}{subsection.14.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.2.2}2. Collaborative Filtering}{144}{subsection.14.2.2}\protected@file@percent }
\newlabel{collaborative-filtering}{{14.2.2}{144}{2. Collaborative Filtering}{subsection.14.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.3}User-Product Matrix}{144}{section.14.3}\protected@file@percent }
\newlabel{user-product-matrix}{{14.3}{144}{User-Product Matrix}{section.14.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.4}Collaborative Filtering Methods}{146}{section.14.4}\protected@file@percent }
\newlabel{collaborative-filtering-methods}{{14.4}{146}{Collaborative Filtering Methods}{section.14.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.1}1. Neighborhood Methods}{146}{subsection.14.4.1}\protected@file@percent }
\newlabel{neighborhood-methods}{{14.4.1}{146}{1. Neighborhood Methods}{subsection.14.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {14.4.2}2. Latent Factor Methods}{148}{subsection.14.4.2}\protected@file@percent }
\newlabel{latent-factor-methods}{{14.4.2}{148}{2. Latent Factor Methods}{subsection.14.4.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.5}Matrix Factorization (MF)}{149}{section.14.5}\protected@file@percent }
\newlabel{matrix-factorization-mf}{{14.5}{149}{Matrix Factorization (MF)}{section.14.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.6}Computational Challenges}{151}{section.14.6}\protected@file@percent }
\newlabel{computational-challenges}{{14.6}{151}{Computational Challenges}{section.14.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {14.7}Beyond Accuracy in Recommender Systems}{152}{section.14.7}\protected@file@percent }
\newlabel{beyond-accuracy-in-recommender-systems}{{14.7}{152}{Beyond Accuracy in Recommender Systems}{section.14.7}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {15}Class Imbalance in Machine Learning}{153}{chapter.15}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{class-imbalance-in-machine-learning}{{15}{153}{Class Imbalance in Machine Learning}{chapter.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {15.1}Categorization of Class Imbalance}{153}{section.15.1}\protected@file@percent }
\newlabel{categorization-of-class-imbalance}{{15.1}{153}{Categorization of Class Imbalance}{section.15.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {15.2}Sampling Techniques}{153}{section.15.2}\protected@file@percent }
\newlabel{sampling-techniques}{{15.2}{153}{Sampling Techniques}{section.15.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.1}Oversampling}{153}{subsection.15.2.1}\protected@file@percent }
\newlabel{oversampling}{{15.2.1}{153}{Oversampling}{subsection.15.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {15.2.1.1}Synthetic Minority Oversampling Technique (SMOTE)}{154}{subsubsection.15.2.1.1}\protected@file@percent }
\newlabel{synthetic-minority-oversampling-technique-smote}{{15.2.1.1}{154}{Synthetic Minority Oversampling Technique (SMOTE)}{subsubsection.15.2.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {15.2.1.2}ADASYN (Adaptive Synthetic Sampling)}{154}{subsubsection.15.2.1.2}\protected@file@percent }
\newlabel{adasyn-adaptive-synthetic-sampling}{{15.2.1.2}{154}{ADASYN (Adaptive Synthetic Sampling)}{subsubsection.15.2.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.2.2}Undersampling}{154}{subsection.15.2.2}\protected@file@percent }
\newlabel{undersampling}{{15.2.2}{154}{Undersampling}{subsection.15.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {15.3}Comparison: SMOTE vs.~ADASYN}{156}{section.15.3}\protected@file@percent }
\newlabel{comparison-smote-vs.-adasyn}{{15.3}{156}{Comparison: SMOTE vs.~ADASYN}{section.15.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {15.3.1}Disadvantages of Oversampling}{156}{subsection.15.3.1}\protected@file@percent }
\newlabel{disadvantages-of-oversampling}{{15.3.1}{156}{Disadvantages of Oversampling}{subsection.15.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {15.4}Evaluation of Classifiers with Imbalanced Data}{159}{section.15.4}\protected@file@percent }
\newlabel{evaluation-of-classifiers-with-imbalanced-data}{{15.4}{159}{Evaluation of Classifiers with Imbalanced Data}{section.15.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {16}Gradient Descent: Optimization in Machine Learning}{160}{chapter.16}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{gradient-descent-optimization-in-machine-learning}{{16}{160}{Gradient Descent: Optimization in Machine Learning}{chapter.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {16.1}The Intuition Behind Gradient Descent}{160}{section.16.1}\protected@file@percent }
\newlabel{the-intuition-behind-gradient-descent}{{16.1}{160}{The Intuition Behind Gradient Descent}{section.16.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {16.2}Mathematical Foundation}{160}{section.16.2}\protected@file@percent }
\newlabel{mathematical-foundation-1}{{16.2}{160}{Mathematical Foundation}{section.16.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {16.3}How Gradient Descent Works}{161}{section.16.3}\protected@file@percent }
\newlabel{how-gradient-descent-works}{{16.3}{161}{How Gradient Descent Works}{section.16.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {16.4}The Learning Rate: A Delicate Balance}{164}{section.16.4}\protected@file@percent }
\newlabel{the-learning-rate-a-delicate-balance}{{16.4}{164}{The Learning Rate: A Delicate Balance}{section.16.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {16.4.1}The Goldilocks Principle in Learning Rates}{164}{subsection.16.4.1}\protected@file@percent }
\newlabel{the-goldilocks-principle-in-learning-rates}{{16.4.1}{164}{The Goldilocks Principle in Learning Rates}{subsection.16.4.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {16.5}Challenges in Gradient Descent}{166}{section.16.5}\protected@file@percent }
\newlabel{challenges-in-gradient-descent}{{16.5}{166}{Challenges in Gradient Descent}{section.16.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {16.5.1}1. Non-Convex Cost Functions}{166}{subsection.16.5.1}\protected@file@percent }
\newlabel{non-convex-cost-functions}{{16.5.1}{166}{1. Non-Convex Cost Functions}{subsection.16.5.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {16.5.2}2. The Ravine Problem}{167}{subsection.16.5.2}\protected@file@percent }
\newlabel{the-ravine-problem}{{16.5.2}{167}{2. The Ravine Problem}{subsection.16.5.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {16.5.3}3. Feature Scaling Issues}{167}{subsection.16.5.3}\protected@file@percent }
\newlabel{feature-scaling-issues}{{16.5.3}{167}{3. Feature Scaling Issues}{subsection.16.5.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {16.5.4}4. Vanishing and Exploding Gradients}{169}{subsection.16.5.4}\protected@file@percent }
\newlabel{vanishing-and-exploding-gradients}{{16.5.4}{169}{4. Vanishing and Exploding Gradients}{subsection.16.5.4}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {17}Types of Gradient Descent}{170}{chapter.17}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{types-of-gradient-descent}{{17}{170}{Types of Gradient Descent}{chapter.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {17.1}1. Batch Gradient Descent}{170}{section.17.1}\protected@file@percent }
\newlabel{batch-gradient-descent}{{17.1}{170}{1. Batch Gradient Descent}{section.17.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {17.1.1}Conceptual Understanding}{170}{subsection.17.1.1}\protected@file@percent }
\newlabel{conceptual-understanding-1}{{17.1.1}{170}{Conceptual Understanding}{subsection.17.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {17.1.2}Key Properties}{170}{subsection.17.1.2}\protected@file@percent }
\newlabel{key-properties}{{17.1.2}{170}{Key Properties}{subsection.17.1.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {17.2}2. Stochastic Gradient Descent (SGD)}{171}{section.17.2}\protected@file@percent }
\newlabel{stochastic-gradient-descent-sgd}{{17.2}{171}{2. Stochastic Gradient Descent (SGD)}{section.17.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {17.2.1}Conceptual Understanding}{171}{subsection.17.2.1}\protected@file@percent }
\newlabel{conceptual-understanding-2}{{17.2.1}{171}{Conceptual Understanding}{subsection.17.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {17.2.2}Key Properties}{171}{subsection.17.2.2}\protected@file@percent }
\newlabel{key-properties-1}{{17.2.2}{171}{Key Properties}{subsection.17.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {17.2.3}Learning Rate Scheduling in SGD}{172}{subsection.17.2.3}\protected@file@percent }
\newlabel{learning-rate-scheduling-in-sgd}{{17.2.3}{172}{Learning Rate Scheduling in SGD}{subsection.17.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {17.3}3. Mini-Batch Gradient Descent}{173}{section.17.3}\protected@file@percent }
\newlabel{mini-batch-gradient-descent}{{17.3}{173}{3. Mini-Batch Gradient Descent}{section.17.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3.1}Conceptual Understanding}{173}{subsection.17.3.1}\protected@file@percent }
\newlabel{conceptual-understanding-3}{{17.3.1}{173}{Conceptual Understanding}{subsection.17.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {17.3.2}Key Properties}{173}{subsection.17.3.2}\protected@file@percent }
\newlabel{key-properties-2}{{17.3.2}{173}{Key Properties}{subsection.17.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {17.4}Theoretical Understanding of Batch Size Impact}{174}{section.17.4}\protected@file@percent }
\newlabel{theoretical-understanding-of-batch-size-impact}{{17.4}{174}{Theoretical Understanding of Batch Size Impact}{section.17.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {17.5}Comparison of Gradient Descent Variants}{174}{section.17.5}\protected@file@percent }
\newlabel{comparison-of-gradient-descent-variants}{{17.5}{174}{Comparison of Gradient Descent Variants}{section.17.5}{}}
\gdef \LT@iv {\LT@entry 
    {1}{60.82828pt}\LT@entry 
    {1}{91.75078pt}\LT@entry 
    {1}{106.70673pt}\LT@entry 
    {1}{131.62923pt}\LT@entry 
    {1}{55.845pt}}
\@writefile{toc}{\contentsline {section}{\numberline {17.6}When to Use Each Variant}{176}{section.17.6}\protected@file@percent }
\newlabel{when-to-use-each-variant}{{17.6}{176}{When to Use Each Variant}{section.17.6}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {18}Advanced Optimization Techniques}{178}{chapter.18}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{advanced-optimization-techniques}{{18}{178}{Advanced Optimization Techniques}{chapter.18}{}}
\@writefile{toc}{\contentsline {section}{\numberline {18.1}Beyond Vanilla Gradient Descent}{178}{section.18.1}\protected@file@percent }
\newlabel{beyond-vanilla-gradient-descent}{{18.1}{178}{Beyond Vanilla Gradient Descent}{section.18.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {18.1.1}1. Momentum}{178}{subsection.18.1.1}\protected@file@percent }
\newlabel{momentum}{{18.1.1}{178}{1. Momentum}{subsection.18.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {18.1.2}2. RMSprop (Root Mean Square Propagation)}{178}{subsection.18.1.2}\protected@file@percent }
\newlabel{rmsprop-root-mean-square-propagation}{{18.1.2}{178}{2. RMSprop (Root Mean Square Propagation)}{subsection.18.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {18.1.3}3. Adam (Adaptive Moment Estimation)}{179}{subsection.18.1.3}\protected@file@percent }
\newlabel{adam-adaptive-moment-estimation}{{18.1.3}{179}{3. Adam (Adaptive Moment Estimation)}{subsection.18.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {18.2}Regularization}{179}{section.18.2}\protected@file@percent }
\newlabel{regularization-1}{{18.2}{179}{Regularization}{section.18.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {18.2.1}L1 Regularization (Lasso)}{179}{subsection.18.2.1}\protected@file@percent }
\newlabel{l1-regularization-lasso}{{18.2.1}{179}{L1 Regularization (Lasso)}{subsection.18.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {18.2.2}L2 Regularization (Ridge)}{180}{subsection.18.2.2}\protected@file@percent }
\newlabel{l2-regularization-ridge}{{18.2.2}{180}{L2 Regularization (Ridge)}{subsection.18.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {18.2.3}Elastic Net}{181}{subsection.18.2.3}\protected@file@percent }
\newlabel{elastic-net}{{18.2.3}{181}{Elastic Net}{subsection.18.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {18.3}Early Stopping}{182}{section.18.3}\protected@file@percent }
\newlabel{early-stopping}{{18.3}{182}{Early Stopping}{section.18.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {18.3.1}Conceptual Understanding}{182}{subsection.18.3.1}\protected@file@percent }
\newlabel{conceptual-understanding-4}{{18.3.1}{182}{Conceptual Understanding}{subsection.18.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {18.4}Early Stopping}{182}{section.18.4}\protected@file@percent }
\newlabel{early-stopping-1}{{18.4}{182}{Early Stopping}{section.18.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {18.5}Batch Normalization}{184}{section.18.5}\protected@file@percent }
\newlabel{batch-normalization}{{18.5}{184}{Batch Normalization}{section.18.5}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {19}Implementing Gradient Descent in Popular Libraries}{185}{chapter.19}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{implementing-gradient-descent-in-popular-libraries}{{19}{185}{Implementing Gradient Descent in Popular Libraries}{chapter.19}{}}
\@writefile{toc}{\contentsline {section}{\numberline {19.1}Using Scikit-Learn}{185}{section.19.1}\protected@file@percent }
\newlabel{using-scikit-learn}{{19.1}{185}{Using Scikit-Learn}{section.19.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {19.2}Using TensorFlow/Keras}{185}{section.19.2}\protected@file@percent }
\newlabel{using-tensorflowkeras}{{19.2}{185}{Using TensorFlow/Keras}{section.19.2}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {20}Conclusion}{187}{chapter.20}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{conclusion-2}{{20}{187}{Conclusion}{chapter.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {20.1}References}{187}{section.20.1}\protected@file@percent }
\newlabel{references-1}{{20.1}{187}{References}{section.20.1}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {21}Neural Networks and Deep Learning Foundations}{188}{chapter.21}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{neural-networks-and-deep-learning-foundations}{{21}{188}{Neural Networks and Deep Learning Foundations}{chapter.21}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.1}ML and Deep Learning History}{188}{section.21.1}\protected@file@percent }
\newlabel{ml-and-deep-learning-history}{{21.1}{188}{ML and Deep Learning History}{section.21.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.1.1}1950s-1960s: Early Developments}{188}{subsection.21.1.1}\protected@file@percent }
\newlabel{s-1960s-early-developments}{{21.1.1}{188}{1950s-1960s: Early Developments}{subsection.21.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.1.2}1970s-1980s: Rise of Connectionism}{189}{subsection.21.1.2}\protected@file@percent }
\newlabel{s-1980s-rise-of-connectionism}{{21.1.2}{189}{1970s-1980s: Rise of Connectionism}{subsection.21.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.1.3}1990s--2000s: Decline \& Rise of Alternatives}{189}{subsection.21.1.3}\protected@file@percent }
\newlabel{s2000s-decline-rise-of-alternatives}{{21.1.3}{189}{1990s--2000s: Decline \& Rise of Alternatives}{subsection.21.1.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.2}Overview of Machine Learning}{189}{section.21.2}\protected@file@percent }
\newlabel{overview-of-machine-learning}{{21.2}{189}{Overview of Machine Learning}{section.21.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.2.1}Core Components}{189}{subsection.21.2.1}\protected@file@percent }
\newlabel{core-components}{{21.2.1}{189}{Core Components}{subsection.21.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.2.2}Key Concepts: Overfitting and Underfitting}{191}{subsection.21.2.2}\protected@file@percent }
\newlabel{key-concepts-overfitting-and-underfitting}{{21.2.2}{191}{Key Concepts: Overfitting and Underfitting}{subsection.21.2.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.3}Neural Networks: From Biological Inspiration to Deep Learning}{191}{section.21.3}\protected@file@percent }
\newlabel{neural-networks-from-biological-inspiration-to-deep-learning}{{21.3}{191}{Neural Networks: From Biological Inspiration to Deep Learning}{section.21.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.3.1}Why Are They Called Neural Networks?}{191}{subsection.21.3.1}\protected@file@percent }
\newlabel{why-are-they-called-neural-networks}{{21.3.1}{191}{Why Are They Called Neural Networks?}{subsection.21.3.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.4}Linearity and Non-Linearity in Neural Networks}{192}{section.21.4}\protected@file@percent }
\newlabel{linearity-and-non-linearity-in-neural-networks}{{21.4}{192}{Linearity and Non-Linearity in Neural Networks}{section.21.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.4.1}The Concept of Linearity}{192}{subsection.21.4.1}\protected@file@percent }
\newlabel{the-concept-of-linearity}{{21.4.1}{192}{The Concept of Linearity}{subsection.21.4.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.4.2}Why We Need Non-Linearity}{192}{subsection.21.4.2}\protected@file@percent }
\newlabel{why-we-need-non-linearity}{{21.4.2}{192}{Why We Need Non-Linearity}{subsection.21.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.4.3}Non-Linearity in Neural Networks}{193}{subsection.21.4.3}\protected@file@percent }
\newlabel{non-linearity-in-neural-networks}{{21.4.3}{193}{Non-Linearity in Neural Networks}{subsection.21.4.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.5}Activation Functions: Adding Non-Linearity}{193}{section.21.5}\protected@file@percent }
\newlabel{activation-functions-adding-non-linearity}{{21.5}{193}{Activation Functions: Adding Non-Linearity}{section.21.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.6}Activation Functions: Understanding the Neural Network's Decision-Making Process}{193}{section.21.6}\protected@file@percent }
\newlabel{activation-functions-understanding-the-neural-networks-decision-making-process}{{21.6}{193}{Activation Functions: Understanding the Neural Network's Decision-Making Process}{section.21.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6.1}The Conceptual Role of Activation Functions}{194}{subsection.21.6.1}\protected@file@percent }
\newlabel{the-conceptual-role-of-activation-functions}{{21.6.1}{194}{The Conceptual Role of Activation Functions}{subsection.21.6.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6.2}Sigmoid Function: The S-Shaped Decision Maker}{194}{subsection.21.6.2}\protected@file@percent }
\newlabel{sigmoid-function-the-s-shaped-decision-maker}{{21.6.2}{194}{Sigmoid Function: The S-Shaped Decision Maker}{subsection.21.6.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6.3}ReLU: The Modern Workhorse}{195}{subsection.21.6.3}\protected@file@percent }
\newlabel{relu-the-modern-workhorse}{{21.6.3}{195}{ReLU: The Modern Workhorse}{subsection.21.6.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6.4}Variants: Leaky ReLU, ELU, and GELU}{197}{subsection.21.6.4}\protected@file@percent }
\newlabel{variants-leaky-relu-elu-and-gelu}{{21.6.4}{197}{Variants: Leaky ReLU, ELU, and GELU}{subsection.21.6.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6.5}Softmax: The Probability Distributor}{199}{subsection.21.6.5}\protected@file@percent }
\newlabel{softmax-the-probability-distributor}{{21.6.5}{199}{Softmax: The Probability Distributor}{subsection.21.6.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6.6}Choosing the Right Activation Function}{199}{subsection.21.6.6}\protected@file@percent }
\newlabel{choosing-the-right-activation-function}{{21.6.6}{199}{Choosing the Right Activation Function}{subsection.21.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6.7}The Mathematics Behind Learning}{200}{subsection.21.6.7}\protected@file@percent }
\newlabel{the-mathematics-behind-learning}{{21.6.7}{200}{The Mathematics Behind Learning}{subsection.21.6.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.6.8}Visualizing Decision Boundaries}{202}{subsection.21.6.8}\protected@file@percent }
\newlabel{visualizing-decision-boundaries}{{21.6.8}{202}{Visualizing Decision Boundaries}{subsection.21.6.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.7}The Role of Bias in Neural Networks}{202}{section.21.7}\protected@file@percent }
\newlabel{the-role-of-bias-in-neural-networks}{{21.7}{202}{The Role of Bias in Neural Networks}{section.21.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.7.1}Understanding Bias in the Statistical Sense}{202}{subsection.21.7.1}\protected@file@percent }
\newlabel{understanding-bias-in-the-statistical-sense}{{21.7.1}{202}{Understanding Bias in the Statistical Sense}{subsection.21.7.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.7.2}Bias Nodes in Neural Networks}{202}{subsection.21.7.2}\protected@file@percent }
\newlabel{bias-nodes-in-neural-networks}{{21.7.2}{202}{Bias Nodes in Neural Networks}{subsection.21.7.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {21.7.3}Practical Implementation in Python}{204}{subsection.21.7.3}\protected@file@percent }
\newlabel{practical-implementation-in-python}{{21.7.3}{204}{Practical Implementation in Python}{subsection.21.7.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.8}Putting It All Together: Building a Neural Network}{205}{section.21.8}\protected@file@percent }
\newlabel{putting-it-all-together-building-a-neural-network}{{21.8}{205}{Putting It All Together: Building a Neural Network}{section.21.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.9}Connection to Deep Learning}{206}{section.21.9}\protected@file@percent }
\newlabel{connection-to-deep-learning}{{21.9}{206}{Connection to Deep Learning}{section.21.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.10}Real-World Analogy: Building a House}{207}{section.21.10}\protected@file@percent }
\newlabel{real-world-analogy-building-a-house}{{21.10}{207}{Real-World Analogy: Building a House}{section.21.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {21.11}Conclusion}{207}{section.21.11}\protected@file@percent }
\newlabel{conclusion-3}{{21.11}{207}{Conclusion}{section.21.11}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {22}Neural Networks Foundations: TLUs, Perceptrons, and MLPs}{208}{chapter.22}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{neural-networks-foundations-tlus-perceptrons-and-mlps}{{22}{208}{Neural Networks Foundations: TLUs, Perceptrons, and MLPs}{chapter.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {22.1}Threshold Logic Units (TLUs)}{208}{section.22.1}\protected@file@percent }
\newlabel{threshold-logic-units-tlus}{{22.1}{208}{Threshold Logic Units (TLUs)}{section.22.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.1.1}The Building Blocks of Neural Networks}{208}{subsection.22.1.1}\protected@file@percent }
\newlabel{the-building-blocks-of-neural-networks}{{22.1.1}{208}{The Building Blocks of Neural Networks}{subsection.22.1.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.1.2}How TLUs Work}{208}{subsection.22.1.2}\protected@file@percent }
\newlabel{how-tlus-work}{{22.1.2}{208}{How TLUs Work}{subsection.22.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.1.3}Analogy: The Voting Committee}{209}{subsection.22.1.3}\protected@file@percent }
\newlabel{analogy-the-voting-committee}{{22.1.3}{209}{Analogy: The Voting Committee}{subsection.22.1.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.1.4}TLUs as Logic Gates}{209}{subsection.22.1.4}\protected@file@percent }
\newlabel{tlus-as-logic-gates}{{22.1.4}{209}{TLUs as Logic Gates}{subsection.22.1.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {22.1.4.1}Example 1: Logical AND Operation (x₁ ∧ x₂)}{209}{subsubsection.22.1.4.1}\protected@file@percent }
\newlabel{example-1-logical-and-operation-xux2081-xux2082}{{22.1.4.1}{209}{Example 1: Logical AND Operation (x₁ ∧ x₂)}{subsubsection.22.1.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {22.1.4.2}Example 2: Logical Implication (x₂ → x₁)}{209}{subsubsection.22.1.4.2}\protected@file@percent }
\newlabel{example-2-logical-implication-xux2082-xux2081}{{22.1.4.2}{209}{Example 2: Logical Implication (x₂ → x₁)}{subsubsection.22.1.4.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.1.5}Python Implementation of a TLU}{209}{subsection.22.1.5}\protected@file@percent }
\newlabel{python-implementation-of-a-tlu}{{22.1.5}{209}{Python Implementation of a TLU}{subsection.22.1.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {22.2}Perceptron}{210}{section.22.2}\protected@file@percent }
\newlabel{perceptron}{{22.2}{210}{Perceptron}{section.22.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {22.2.1}The First Learning Neural Network}{210}{subsection.22.2.1}\protected@file@percent }
\newlabel{the-first-learning-neural-network}{{22.2.1}{210}{The First Learning Neural Network}{subsection.22.2.1}{}}
